{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "date_accuracy_check2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/iamrajee/Data-Analysis/blob/master/date_accuracy_check2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "8_oOdINFafSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2f6ab12a-a762-434e-e04a-a95d22fc4d98"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  drive\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KNopIMWtsoM0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !rm model_final4.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DcFplAmpM2ic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "# !apt-get update -qq 2>&1 > /dev/null\n",
        "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# creds = GoogleCredentials.get_application_default()\n",
        "# import getpass\n",
        "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "# vcode = getpass.getpass()\n",
        "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# !mkdir -p drive\n",
        "# !google-drive-ocamlfuse drive\n",
        "\n",
        "\n",
        "# !ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7r8pgLljM8PH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wxdqUUVAetnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "y_train_df = pd.read_csv(\"drive/finaldates/datefinal3.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZHr9kZGGevO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "b63908f8-9284-4460-dc63-41f7d4d7b996"
      },
      "cell_type": "code",
      "source": [
        "y_all = y_train_df['0']\n",
        "print(y_all[4332])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1921.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SkCLhdQtexLy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i,ele in enumerate(y_all):\n",
        "#   y_all[i] = (ele-1900)//5\n",
        "\n",
        "# from sklearn.preprocessing import LabelBinarizer\n",
        "# encoder = LabelBinarizer()\n",
        "# transfomed_label = encoder.fit_transform(y_all)\n",
        "# Y = transfomed_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zkAMyoEOJnsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "77dc74b0-5700-4395-dd22-f942410d707f"
      },
      "cell_type": "code",
      "source": [
        "!pip install h5py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\r\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.14.5)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.11.0)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XSwjaLWiSNZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a=numpy.array(Image.open(inraster)) #raster is .tif Float32, size 561x253\n",
        "# newIm=Image.new(Im.mode, Im.size)\n",
        "# Image.fromarray(a).save(outraster)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzI-b6bTeysH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "c2c6f65f-9348-4d84-f8db-3c014ac38554"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "#\n",
        "import os\n",
        "import time\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from keras import optimizers\n",
        "import h5py\n",
        "#\n",
        "\n",
        "\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras import backend as k\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard,EarlyStopping"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rE-Cz7iUe7sv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_width, img_height = 256, 256\n",
        "\n",
        "# batch_size = 16\n",
        "# epochs = 50\n",
        "\n",
        "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrBA9UHXYqIL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4816
        },
        "collapsed": true,
        "outputId": "4f8040ed-8dd4-47c3-aa1e-a5421c11cf1d"
      },
      "cell_type": "code",
      "source": [
        "path1 = \"drive/new_images\"\n",
        "main_data_dir_list = os.listdir(path1)\n",
        "main_data_dir_list = sorted(main_data_dir_list, key=lambda x: x)\n",
        "\n",
        "\n",
        "\n",
        "allimg_data_list=[]\n",
        "\n",
        "for dataset in main_data_dir_list:\n",
        "  img_list=os.listdir(path1+'/'+ dataset)\n",
        "  img_list = sorted(img_list, key=lambda x: x)\n",
        "  print ('Loaded the img of dataset-'+'{}\\n'.format(dataset))\n",
        "  for img in img_list:\n",
        "    if img.endswith(\".jpg\"):\n",
        "      path2 = path1+'/'+ dataset+'/'+ img\n",
        "      allimg_data_list.append(path2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the img of dataset-Adolf_Holzel\n",
            "\n",
            "Loaded the img of dataset-Aleksandr_Rodchenko\n",
            "\n",
            "Loaded the img of dataset-Aleksandr_Vesnin\n",
            "\n",
            "Loaded the img of dataset-Aleksandra_Ekster\n",
            "\n",
            "Loaded the img of dataset-Aleksei_Kruchenykh\n",
            "\n",
            "Loaded the img of dataset-Alfred_Auguste_Janniot\n",
            "\n",
            "Loaded the img of dataset-Alfred_Stieglitz\n",
            "\n",
            "Loaded the img of dataset-Alphonse_Maria_Mucha\n",
            "\n",
            "Loaded the img of dataset-Alvin Langdon Coburn\n",
            "\n",
            "Loaded the img of dataset-Angelo_Rognoni\n",
            "\n",
            "Loaded the img of dataset-Anton_Giulio_Bragaglia\n",
            "\n",
            "Loaded the img of dataset-Ardengo_Soffici\n",
            "\n",
            "Loaded the img of dataset-Arthur Dove\n",
            "\n",
            "Loaded the img of dataset-August_Endell\n",
            "\n",
            "Loaded the img of dataset-Auguste_Charles_Louis_Oleffe\n",
            "\n",
            "Loaded the img of dataset-Augusto_Giacometti\n",
            "\n",
            "Loaded the img of dataset-Augusto_Giacometti (507f21e7)\n",
            "\n",
            "Loaded the img of dataset-Bart_van_der_Leck\n",
            "\n",
            "Loaded the img of dataset-Bernhard_Pankok\n",
            "\n",
            "Loaded the img of dataset-Carlo_Carra\n",
            "\n",
            "Loaded the img of dataset-Charles_Demuth\n",
            "\n",
            "Loaded the img of dataset-Christian_Schad-2\n",
            "\n",
            "Loaded the img of dataset-Claude_Monet1\n",
            "\n",
            "Loaded the img of dataset-Dagobert_Peche\n",
            "\n",
            "Loaded the img of dataset-David_Davidovich_Burlyuk\n",
            "\n",
            "Loaded the img of dataset-Duncan_Grant\n",
            "\n",
            "Loaded the img of dataset-Eliezer__El__Lissitzky\n",
            "\n",
            "Loaded the img of dataset-Ella_Bergmann_Michel\n",
            "\n",
            "Loaded the img of dataset-Emilio_Pettoruti\n",
            "\n",
            "Loaded the img of dataset-Fernand_Leger_3\n",
            "\n",
            "Loaded the img of dataset-Filippo_Tommaso_Marinetti\n",
            "\n",
            "Loaded the img of dataset-Fortunato_Depero\n",
            "\n",
            "Loaded the img of dataset-Fortunato_Depero (e8d1cb91)\n",
            "\n",
            "Loaded the img of dataset-Frances_MacDonald\n",
            "\n",
            "Loaded the img of dataset-Francesco_Cangiullo\n",
            "\n",
            "Loaded the img of dataset-Franz_Wilhelm_Seiwert_\n",
            "\n",
            "Loaded the img of dataset-Franz_von_Stuck\n",
            "\n",
            "Loaded the img of dataset-Fritz_Hellmut_Ehmcke\n",
            "\n",
            "Loaded the img of dataset-Georges_Braque_1\n",
            "\n",
            "Loaded the img of dataset-Georges_Ribemont_Dessaignes_\n",
            "\n",
            "Loaded the img of dataset-Georges_de_Feure\n",
            "\n",
            "Loaded the img of dataset-Georgia_O_Keeffe_1\n",
            "\n",
            "Loaded the img of dataset-Gertrud_Arndt\n",
            "\n",
            "Loaded the img of dataset-Gustav_Gustavovich_Klucis_\n",
            "\n",
            "Loaded the img of dataset-Gustav_Klutsis\n",
            "\n",
            "Loaded the img of dataset-Hannah_or_Hanna_Höch\n",
            "\n",
            "Loaded the img of dataset-Hans_Arp\n",
            "\n",
            "Loaded the img of dataset-Hans_Baluschek\n",
            "\n",
            "Loaded the img of dataset-Hans_Richter\n",
            "\n",
            "Loaded the img of dataset-Hector_Guimard\n",
            "\n",
            "Loaded the img of dataset-Henri_Charles_Manguin_\n",
            "\n",
            "Loaded the img of dataset-Henri_Gaudier_Brzeska\n",
            "\n",
            "Loaded the img of dataset-Henry_Moore1\n",
            "\n",
            "Loaded the img of dataset-Henryk_Berlewi\n",
            "\n",
            "Loaded the img of dataset-Henryk_Berlewi (02bc8dd0)\n",
            "\n",
            "Loaded the img of dataset-Hilaire_Germain_Edgar_Degas\n",
            "\n",
            "Loaded the img of dataset-Hugo_Leven\n",
            "\n",
            "Loaded the img of dataset-Hugo_von_Habermann\n",
            "\n",
            "Loaded the img of dataset-Igor_Emmanuelovich_Grabar_\n",
            "\n",
            "Loaded the img of dataset-Ilia_Chashnik\n",
            "\n",
            "Loaded the img of dataset-Ivan_Kliun\n",
            "\n",
            "Loaded the img of dataset-Jean_Baptiste_Armand_Guillaumin\n",
            "\n",
            "Loaded the img of dataset-Jindrich_Styrsky\n",
            "\n",
            "Loaded the img of dataset-Joan_Miró1\n",
            "\n",
            "Loaded the img of dataset-Johann_Wilhelm_or_Jean_de_von_Tscharner\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded the img of dataset-Johannes_Baader\n",
            "\n",
            "Loaded the img of dataset-John_Covert\n",
            "\n",
            "Loaded the img of dataset-John_Heartfield\n",
            "\n",
            "Loaded the img of dataset-Joseph_Stella\n",
            "\n",
            "Loaded the img of dataset-Jules_Schmalzigaug\n",
            "\n",
            "Loaded the img of dataset-Kasimir_Malevich_2\n",
            "\n",
            "Loaded the img of dataset-Katarzyna_Kobro\n",
            "\n",
            "Loaded the img of dataset-Konstantin_Fedorovich_Yuon\n",
            "\n",
            "Loaded the img of dataset-Kurt_Schwitters\n",
            "\n",
            "Loaded the img of dataset-Laszlo_Moholy_Nagy\n",
            "\n",
            "Loaded the img of dataset-Lawrence_Atkinson\n",
            "\n",
            "Loaded the img of dataset-Leonardo_Bistolfi\n",
            "\n",
            "Loaded the img of dataset-Liubov_Popova\n",
            "\n",
            "Loaded the img of dataset-Ludwig_Heinrich_Jungnickel\n",
            "\n",
            "Loaded the img of dataset-Léon_Bakst\n",
            "\n",
            "Loaded the img of dataset-Manuel_Orazi_\n",
            "\n",
            "Loaded the img of dataset-Marcel_Janco\n",
            "\n",
            "Loaded the img of dataset-Marice_Marinot\n",
            "\n",
            "Loaded the img of dataset-Max_Ernst1\n",
            "\n",
            "Loaded the img of dataset-Max_Slevogt\n",
            "\n",
            "Loaded the img of dataset-Mikhail_Larionov\n",
            "\n",
            "Loaded the img of dataset-Mikhail_Matiushin\n",
            "\n",
            "Loaded the img of dataset-Morgan_Russell\n",
            "\n",
            "Loaded the img of dataset-Morton_Livingston_Schamberg\n",
            "\n",
            "Loaded the img of dataset-Nikolaï_Ivanovich_Kalmakov\n",
            "\n",
            "Loaded the img of dataset-Niles_Spencer\n",
            "\n",
            "Loaded the img of dataset-Ol_ga_Vladimirovna_Rozanova\n",
            "\n",
            "Loaded the img of dataset-Oskar_Nerlinger\n",
            "\n",
            "Loaded the img of dataset-Oskar_Schlemmer\n",
            "\n",
            "Loaded the img of dataset-Otto_Gussmann\n",
            "\n",
            "Loaded the img of dataset-Patrick_Henry_Bruce\n",
            "\n",
            "Loaded the img of dataset-Patriz_Huber\n",
            "\n",
            "Loaded the img of dataset-Paul_Citroen\n",
            "\n",
            "Loaded the img of dataset-Paul_Nash\n",
            "\n",
            "Loaded the img of dataset-Paul_Outerbridge\n",
            "\n",
            "Loaded the img of dataset-Paul_Scheurich\n",
            "\n",
            "Loaded the img of dataset-Paul_Strand_1\n",
            "\n",
            "Loaded the img of dataset-Pavel_Dmitrievich_Korin\n",
            "\n",
            "Loaded the img of dataset-Peter_Auguste_Böckstiegel\n",
            "\n",
            "Loaded the img of dataset-Peter_Behrens\n",
            "\n",
            "Loaded the img of dataset-Piet Mondrian\n",
            "\n",
            "Loaded the img of dataset-René_Buthaud\n",
            "\n",
            "Loaded the img of dataset-René_François_Ghislain_Magritte\n",
            "\n",
            "Loaded the img of dataset-René_J__Lalique\n",
            "\n",
            "Loaded the img of dataset-Rik_Wouters\n",
            "\n",
            "Loaded the img of dataset-Robert_Michel\n",
            "\n",
            "Loaded the img of dataset-Rose_O_Neill\n",
            "\n",
            "Loaded the img of dataset-Rougena_or_Rougina_Zatková\n",
            "\n",
            "Loaded the img of dataset-Sandor_Bortnyik\n",
            "\n",
            "Loaded the img of dataset-Sonia Delaunay Terk\n",
            "\n",
            "Loaded the img of dataset-Sophie Taeuber\n",
            "\n",
            "Loaded the img of dataset-Sophie_Henriette_Taeuber_Arp\n",
            "\n",
            "Loaded the img of dataset-Stanton Macdonald Wright\n",
            "\n",
            "Loaded the img of dataset-Suzanne Duchamp\n",
            "\n",
            "Loaded the img of dataset-Theo van Doesburg\n",
            "\n",
            "Loaded the img of dataset-Varvara_Fedorovna_Stepanova\n",
            "\n",
            "Loaded the img of dataset-Vasily_Kandinsky_2\n",
            "\n",
            "Loaded the img of dataset-Vaslav_Nijinsky\n",
            "\n",
            "Loaded the img of dataset-Viking_Eggeling\n",
            "\n",
            "Loaded the img of dataset-Vilmos Huszar\n",
            "\n",
            "Loaded the img of dataset-Virgilio_Marchi\n",
            "\n",
            "Loaded the img of dataset-Vladimir Tatlin\n",
            "\n",
            "Loaded the img of dataset-Vladimir_Avgustovich_Stenberg\n",
            "\n",
            "Loaded the img of dataset-Walter_Crane\n",
            "\n",
            "Loaded the img of dataset-Wilhelm_or_Heinrich_Wilhelm_Trübner\n",
            "\n",
            "Loaded the img of dataset-William_Frend_De_Morgan\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded the img of dataset-William_Richard_Lethaby\n",
            "\n",
            "Loaded the img of dataset-Władysław Strzemiński\n",
            "\n",
            "Loaded the img of dataset-aleks\n",
            "\n",
            "Loaded the img of dataset-docProps\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XsHvTJaMZ9dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c899169-4322-4ba3-af3e-b12a52591210"
      },
      "cell_type": "code",
      "source": [
        "# y_all\n",
        "# 8632\n",
        "print(len(allimg_data_list))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DG0bboS7b3D6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1581
        },
        "outputId": "7d8aac56-7b82-4ee6-e9fb-91d5b4c45e78"
      },
      "cell_type": "code",
      "source": [
        "img_data_list = []\n",
        "\n",
        "sorted_files = sorted(allimg_data_list, key=lambda x: x)\n",
        "print(len(sorted_files))\n",
        "\n",
        "\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "for i,img in enumerate(sorted_files):\n",
        "  img2 = image.load_img(img, target_size=(256, 256))\n",
        "  x = image.img_to_array(img2)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x = preprocess_input(x)\n",
        "  img_data_list.append(x)\n",
        "  if i%100==0:\n",
        "    print(i)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8632\n",
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "8200\n",
            "8300\n",
            "8400\n",
            "8500\n",
            "8600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ohb3-73TIU1z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(r)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u7cTrYYy6Oi7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0add28e8-09cc-471b-fbbb-4f169330d77c"
      },
      "cell_type": "code",
      "source": [
        "print(type(img_data_list))\n",
        "print(type(img_data_list[0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y7tsGG2eYXhh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nm_v9iWmImrd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i,image in enumerate(img_data_list):\n",
        "  img_data_list[i] = image[0]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G8K6UPP7610r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print( np.shape(img_data_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZrhWXf8dsMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f3ee82c-d198-482e-ceec-48843edde894"
      },
      "cell_type": "code",
      "source": [
        "print(len(img_data_list), len(y_all))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8632 8632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OLdqcelmi00s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a062f034-cebf-4680-f757-c92e9a7057fd"
      },
      "cell_type": "code",
      "source": [
        "print(np.shape(img_data_list[0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kFNJ6MeZGxOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "eb262e6b-43e4-4769-ecdc-9f0e7831b6b6"
      },
      "cell_type": "code",
      "source": [
        "print(y_all[8608],type(y_all[8608]))\n",
        "\n",
        "print(y_all[8609],type(y_all[8609]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nan <class 'numpy.float64'>\n",
            "1888.0 <class 'numpy.float64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8RDjOL6odtmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "af75d3a6-ce2b-44bd-e6a0-127042eb3c3f"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_data = []\n",
        "y_data1 = []\n",
        "\n",
        "for i,date in enumerate(y_all):\n",
        "  if str(y_all[i]).lower() != \"nan\":\n",
        "    y_data1.append(date)\n",
        "    x_data.append(img_data_list[i])\n",
        "    \n",
        "  \n",
        "  \n",
        "print(len(img_data_list),len(y_all))  \n",
        "print(len(x_data),len(y_data1))\n",
        "\n",
        "\n",
        "print(len(np.unique(y_data1)))\n",
        "print(np.unique(y_data1))\n",
        "# 8632 8632\n",
        "# 7886 7886"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8632 8632\n",
            "7886 7886\n",
            "139\n",
            "[1850. 1851. 1852. 1853. 1854. 1856. 1857. 1858. 1859. 1860. 1861. 1862.\n",
            " 1863. 1864. 1865. 1866. 1867. 1868. 1869. 1870. 1871. 1872. 1873. 1874.\n",
            " 1875. 1876. 1877. 1878. 1879. 1880. 1881. 1882. 1883. 1884. 1885. 1886.\n",
            " 1887. 1888. 1889. 1890. 1891. 1892. 1893. 1894. 1895. 1896. 1897. 1898.\n",
            " 1899. 1900. 1901. 1902. 1903. 1904. 1905. 1906. 1907. 1908. 1909. 1910.\n",
            " 1911. 1912. 1913. 1914. 1915. 1916. 1917. 1918. 1919. 1920. 1921. 1922.\n",
            " 1923. 1924. 1925. 1926. 1927. 1928. 1929. 1930. 1931. 1932. 1933. 1934.\n",
            " 1935. 1936. 1937. 1938. 1939. 1940. 1941. 1942. 1943. 1944. 1945. 1946.\n",
            " 1947. 1948. 1949. 1950. 1951. 1952. 1953. 1954. 1955. 1956. 1957. 1958.\n",
            " 1959. 1960. 1961. 1962. 1963. 1964. 1965. 1966. 1967. 1968. 1969. 1970.\n",
            " 1971. 1972. 1973. 1974. 1975. 1976. 1977. 1978. 1979. 1980. 1981. 1982.\n",
            " 1983. 1984. 1986. 1987. 1992. 1993. 1996.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h-IdYs2iZwEu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# pickle_out = open(\"imagedata.pickle\",\"wb\")\n",
        "# pickle.dump(x_data, pickle_out)\n",
        "# pickle_out.close()\n",
        "\n",
        "# !ls\n",
        "\n",
        "# pickle_in = open(\"imagedata.pickle\",\"rb\")\n",
        "# x_data_check = pickle.load(pickle_in)\n",
        "# print(len(x_data_check), type(x_data_check), x_data_check[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zpPMhYP-mSEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "285ffeff-187e-40cc-c64e-8afcb74b20ff"
      },
      "cell_type": "code",
      "source": [
        "print(len(x_data),len(y_data1),len(img_data_list),len(y_all))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7886 7886 8632 8632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DXW3YgvHG7hT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c8a2240-9d7b-445f-c92e-87836cb43927"
      },
      "cell_type": "code",
      "source": [
        "print(min(y_data1),max(y_data1))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1850.0 1996.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XVdpOes8gTaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d5f99cd2-a1f5-472e-89b1-60ea4b4ab321"
      },
      "cell_type": "code",
      "source": [
        "for i,ele in enumerate(y_data1):\n",
        "  y_data1[i] = (ele-1850)//5\n",
        "  \n",
        "print(y_data1)\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()\n",
        "transfomed_label = encoder.fit_transform(y_data1)\n",
        "y_data = transfomed_label\n",
        "print(np.shape(y_data))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15.0, 11.0, 13.0, 13.0, 11.0, 13.0, 15.0, 15.0, 14.0, 14.0, 15.0, 16.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 13.0, 15.0, 14.0, 16.0, 15.0, 16.0, 15.0, 15.0, 16.0, 15.0, 15.0, 16.0, 14.0, 14.0, 15.0, 15.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 14.0, 14.0, 14.0, 16.0, 14.0, 17.0, 14.0, 14.0, 14.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 15.0, 17.0, 15.0, 16.0, 16.0, 16.0, 16.0, 17.0, 17.0, 13.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 13.0, 13.0, 14.0, 14.0, 15.0, 15.0, 14.0, 15.0, 12.0, 27.0, 12.0, 12.0, 12.0, 12.0, 13.0, 12.0, 12.0, 16.0, 16.0, 11.0, 15.0, 15.0, 15.0, 15.0, 13.0, 11.0, 15.0, 13.0, 15.0, 23.0, 15.0, 15.0, 16.0, 23.0, 15.0, 16.0, 23.0, 13.0, 13.0, 23.0, 23.0, 15.0, 13.0, 13.0, 13.0, 21.0, 15.0, 13.0, 16.0, 16.0, 15.0, 15.0, 12.0, 15.0, 17.0, 15.0, 19.0, 15.0, 21.0, 15.0, 14.0, 15.0, 15.0, 13.0, 13.0, 14.0, 14.0, 21.0, 15.0, 18.0, 14.0, 18.0, 14.0, 18.0, 15.0, 18.0, 16.0, 14.0, 15.0, 23.0, 16.0, 16.0, 12.0, 14.0, 23.0, 17.0, 25.0, 13.0, 16.0, 14.0, 17.0, 10.0, 17.0, 26.0, 13.0, 13.0, 11.0, 14.0, 16.0, 16.0, 15.0, 13.0, 13.0, 17.0, 17.0, 20.0, 20.0, 10.0, 16.0, 16.0, 13.0, 13.0, 14.0, 17.0, 16.0, 13.0, 16.0, 13.0, 16.0, 16.0, 14.0, 16.0, 14.0, 14.0, 13.0, 14.0, 12.0, 13.0, 14.0, 12.0, 13.0, 13.0, 17.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 16.0, 13.0, 16.0, 15.0, 13.0, 16.0, 15.0, 13.0, 13.0, 13.0, 12.0, 13.0, 12.0, 13.0, 16.0, 12.0, 13.0, 16.0, 16.0, 14.0, 16.0, 16.0, 16.0, 15.0, 13.0, 14.0, 13.0, 16.0, 15.0, 14.0, 14.0, 19.0, 15.0, 16.0, 15.0, 13.0, 13.0, 14.0, 14.0, 17.0, 15.0, 23.0, 16.0, 15.0, 14.0, 23.0, 19.0, 26.0, 13.0, 20.0, 26.0, 16.0, 22.0, 26.0, 15.0, 26.0, 14.0, 13.0, 15.0, 13.0, 12.0, 13.0, 16.0, 16.0, 15.0, 14.0, 11.0, 14.0, 16.0, 15.0, 19.0, 16.0, 15.0, 13.0, 14.0, 15.0, 13.0, 21.0, 15.0, 15.0, 13.0, 15.0, 17.0, 13.0, 10.0, 15.0, 14.0, 15.0, 19.0, 13.0, 15.0, 15.0, 16.0, 15.0, 14.0, 16.0, 14.0, 11.0, 13.0, 15.0, 13.0, 13.0, 16.0, 12.0, 14.0, 11.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 11.0, 14.0, 16.0, 14.0, 12.0, 12.0, 14.0, 19.0, 12.0, 14.0, 14.0, 21.0, 18.0, 14.0, 16.0, 14.0, 17.0, 10.0, 13.0, 14.0, 14.0, 16.0, 14.0, 14.0, 10.0, 16.0, 18.0, 14.0, 11.0, 16.0, 17.0, 15.0, 11.0, 16.0, 13.0, 13.0, 14.0, 17.0, 13.0, 14.0, 11.0, 19.0, 11.0, 11.0, 17.0, 13.0, 12.0, 11.0, 16.0, 12.0, 16.0, 11.0, 14.0, 16.0, 17.0, 15.0, 16.0, 13.0, 13.0, 12.0, 13.0, 14.0, 12.0, 14.0, 12.0, 13.0, 12.0, 16.0, 16.0, 10.0, 15.0, 16.0, 13.0, 12.0, 12.0, 16.0, 14.0, 12.0, 14.0, 12.0, 14.0, 14.0, 15.0, 11.0, 13.0, 16.0, 14.0, 12.0, 13.0, 15.0, 15.0, 11.0, 16.0, 11.0, 15.0, 14.0, 16.0, 11.0, 15.0, 14.0, 10.0, 16.0, 14.0, 16.0, 15.0, 16.0, 17.0, 15.0, 16.0, 17.0, 20.0, 15.0, 11.0, 14.0, 12.0, 17.0, 14.0, 14.0, 16.0, 13.0, 15.0, 16.0, 16.0, 14.0, 16.0, 15.0, 13.0, 17.0, 15.0, 13.0, 17.0, 16.0, 13.0, 15.0, 14.0, 8.0, 17.0, 15.0, 13.0, 14.0, 15.0, 13.0, 16.0, 15.0, 15.0, 13.0, 14.0, 13.0, 9.0, 13.0, 13.0, 12.0, 12.0, 10.0, 13.0, 13.0, 13.0, 12.0, 11.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 12.0, 13.0, 11.0, 11.0, 13.0, 11.0, 11.0, 12.0, 13.0, 13.0, 11.0, 12.0, 11.0, 13.0, 11.0, 11.0, 13.0, 11.0, 11.0, 11.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 13.0, 22.0, 12.0, 13.0, 12.0, 13.0, 13.0, 13.0, 10.0, 12.0, 11.0, 13.0, 13.0, 13.0, 11.0, 12.0, 12.0, 12.0, 13.0, 12.0, 11.0, 12.0, 11.0, 13.0, 13.0, 13.0, 12.0, 13.0, 12.0, 11.0, 13.0, 11.0, 10.0, 13.0, 12.0, 11.0, 13.0, 12.0, 13.0, 10.0, 15.0, 11.0, 12.0, 12.0, 11.0, 11.0, 13.0, 12.0, 11.0, 12.0, 11.0, 13.0, 12.0, 11.0, 10.0, 12.0, 11.0, 10.0, 11.0, 13.0, 11.0, 13.0, 10.0, 11.0, 13.0, 11.0, 11.0, 12.0, 11.0, 13.0, 12.0, 11.0, 13.0, 11.0, 10.0, 11.0, 12.0, 12.0, 12.0, 12.0, 13.0, 12.0, 11.0, 12.0, 13.0, 10.0, 11.0, 11.0, 13.0, 12.0, 13.0, 10.0, 10.0, 12.0, 13.0, 12.0, 11.0, 12.0, 12.0, 11.0, 12.0, 13.0, 12.0, 13.0, 12.0, 13.0, 11.0, 10.0, 12.0, 12.0, 12.0, 12.0, 13.0, 14.0, 11.0, 12.0, 10.0, 12.0, 11.0, 11.0, 13.0, 13.0, 13.0, 12.0, 11.0, 10.0, 11.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 11.0, 10.0, 12.0, 11.0, 11.0, 11.0, 12.0, 10.0, 11.0, 13.0, 13.0, 11.0, 11.0, 13.0, 11.0, 12.0, 11.0, 11.0, 10.0, 11.0, 13.0, 13.0, 11.0, 11.0, 13.0, 13.0, 11.0, 13.0, 11.0, 11.0, 11.0, 11.0, 11.0, 20.0, 12.0, 10.0, 10.0, 11.0, 11.0, 11.0, 11.0, 20.0, 13.0, 10.0, 12.0, 11.0, 11.0, 10.0, 12.0, 13.0, 22.0, 11.0, 11.0, 11.0, 13.0, 11.0, 12.0, 10.0, 12.0, 13.0, 11.0, 22.0, 12.0, 11.0, 11.0, 12.0, 13.0, 11.0, 13.0, 12.0, 12.0, 13.0, 12.0, 11.0, 12.0, 13.0, 10.0, 13.0, 12.0, 12.0, 12.0, 10.0, 13.0, 13.0, 10.0, 13.0, 12.0, 10.0, 13.0, 13.0, 11.0, 12.0, 10.0, 13.0, 10.0, 10.0, 11.0, 12.0, 12.0, 13.0, 12.0, 10.0, 10.0, 11.0, 12.0, 10.0, 13.0, 13.0, 10.0, 12.0, 11.0, 22.0, 12.0, 13.0, 13.0, 10.0, 12.0, 13.0, 13.0, 13.0, 11.0, 12.0, 12.0, 13.0, 11.0, 12.0, 13.0, 13.0, 12.0, 11.0, 13.0, 11.0, 12.0, 12.0, 11.0, 12.0, 11.0, 14.0, 12.0, 13.0, 13.0, 11.0, 12.0, 11.0, 11.0, 13.0, 13.0, 12.0, 12.0, 12.0, 11.0, 13.0, 11.0, 13.0, 11.0, 12.0, 13.0, 13.0, 11.0, 12.0, 11.0, 13.0, 12.0, 11.0, 13.0, 11.0, 12.0, 13.0, 11.0, 12.0, 13.0, 13.0, 13.0, 11.0, 12.0, 11.0, 11.0, 13.0, 11.0, 12.0, 11.0, 13.0, 12.0, 12.0, 11.0, 12.0, 13.0, 11.0, 12.0, 12.0, 12.0, 12.0, 11.0, 12.0, 13.0, 14.0, 11.0, 13.0, 12.0, 11.0, 11.0, 12.0, 13.0, 11.0, 12.0, 11.0, 11.0, 13.0, 11.0, 10.0, 11.0, 11.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 11.0, 11.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 13.0, 13.0, 13.0, 11.0, 11.0, 12.0, 11.0, 13.0, 13.0, 13.0, 12.0, 13.0, 13.0, 11.0, 13.0, 10.0, 13.0, 12.0, 10.0, 20.0, 12.0, 13.0, 13.0, 12.0, 12.0, 17.0, 12.0, 13.0, 12.0, 11.0, 12.0, 11.0, 13.0, 12.0, 13.0, 12.0, 12.0, 13.0, 13.0, 12.0, 13.0, 13.0, 12.0, 12.0, 12.0, 13.0, 12.0, 13.0, 12.0, 12.0, 13.0, 12.0, 13.0, 12.0, 12.0, 11.0, 12.0, 13.0, 13.0, 13.0, 12.0, 13.0, 11.0, 11.0, 11.0, 13.0, 13.0, 11.0, 11.0, 13.0, 12.0, 13.0, 12.0, 22.0, 11.0, 13.0, 12.0, 12.0, 13.0, 13.0, 11.0, 13.0, 12.0, 13.0, 12.0, 11.0, 11.0, 13.0, 13.0, 11.0, 13.0, 13.0, 11.0, 11.0, 11.0, 13.0, 11.0, 11.0, 13.0, 12.0, 11.0, 13.0, 11.0, 11.0, 13.0, 13.0, 13.0, 11.0, 12.0, 11.0, 13.0, 12.0, 12.0, 13.0, 11.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 12.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 16.0, 18.0, 18.0, 18.0, 17.0, 16.0, 17.0, 16.0, 17.0, 17.0, 17.0, 16.0, 17.0, 15.0, 18.0, 16.0, 17.0, 14.0, 18.0, 16.0, 15.0, 17.0, 18.0, 17.0, 15.0, 18.0, 14.0, 18.0, 17.0, 16.0, 16.0, 18.0, 18.0, 19.0, 18.0, 17.0, 18.0, 18.0, 18.0, 19.0, 19.0, 19.0, 19.0, 18.0, 18.0, 19.0, 17.0, 17.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 15.0, 18.0, 17.0, 17.0, 18.0, 17.0, 16.0, 12.0, 18.0, 14.0, 18.0, 17.0, 18.0, 15.0, 19.0, 16.0, 17.0, 17.0, 17.0, 15.0, 16.0, 18.0, 16.0, 15.0, 18.0, 12.0, 16.0, 17.0, 16.0, 16.0, 18.0, 17.0, 15.0, 18.0, 17.0, 18.0, 18.0, 12.0, 15.0, 17.0, 15.0, 15.0, 18.0, 17.0, 17.0, 18.0, 17.0, 15.0, 18.0, 12.0, 18.0, 17.0, 17.0, 15.0, 16.0, 18.0, 17.0, 17.0, 14.0, 18.0, 16.0, 17.0, 15.0, 17.0, 12.0, 17.0, 12.0, 12.0, 18.0, 18.0, 16.0, 18.0, 15.0, 15.0, 17.0, 17.0, 18.0, 16.0, 14.0, 16.0, 16.0, 17.0, 18.0, 18.0, 17.0, 18.0, 15.0, 18.0, 14.0, 18.0, 17.0, 18.0, 18.0, 15.0, 18.0, 18.0, 18.0, 14.0, 18.0, 18.0, 12.0, 15.0, 15.0, 17.0, 17.0, 16.0, 18.0, 18.0, 17.0, 9.0, 22.0, 21.0, 21.0, 22.0, 21.0, 22.0, 21.0, 21.0, 21.0, 22.0, 14.0, 22.0, 22.0, 21.0, 21.0, 21.0, 13.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 21.0, 22.0, 22.0, 22.0, 21.0, 21.0, 22.0, 21.0, 22.0, 21.0, 22.0, 21.0, 22.0, 22.0, 21.0, 14.0, 22.0, 22.0, 21.0, 22.0, 21.0, 21.0, 21.0, 21.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 22.0, 11.0, 13.0, 13.0, 10.0, 13.0, 12.0, 14.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 12.0, 12.0, 12.0, 13.0, 13.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 15.0, 12.0, 12.0, 14.0, 13.0, 13.0, 13.0, 13.0, 14.0, 16.0, 13.0, 13.0, 13.0, 13.0, 14.0, 13.0, 13.0, 13.0, 13.0, 15.0, 16.0, 15.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 15.0, 13.0, 13.0, 13.0, 13.0, 16.0, 14.0, 15.0, 13.0, 13.0, 14.0, 16.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 15.0, 13.0, 13.0, 13.0, 13.0, 16.0, 15.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 15.0, 14.0, 15.0, 13.0, 13.0, 13.0, 13.0, 15.0, 14.0, 15.0, 13.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 13.0, 15.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 13.0, 13.0, 13.0, 13.0, 14.0, 13.0, 13.0, 15.0, 15.0, 13.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 14.0, 16.0, 6.0, 4.0, 9.0, 5.0, 8.0, 5.0, 6.0, 4.0, 3.0, 7.0, 3.0, 8.0, 5.0, 6.0, 15.0, 4.0, 8.0, 3.0, 6.0, 6.0, 6.0, 11.0, 7.0, 6.0, 6.0, 7.0, 5.0, 4.0, 7.0, 10.0, 15.0, 4.0, 4.0, 6.0, 5.0, 6.0, 5.0, 5.0, 15.0, 2.0, 10.0, 6.0, 7.0, 10.0, 7.0, 10.0, 4.0, 6.0, 11.0, 7.0, 9.0, 11.0, 7.0, 7.0, 6.0, 10.0, 6.0, 5.0, 3.0, 3.0, 4.0, 4.0, 3.0, 12.0, 3.0, 5.0, 6.0, 6.0, 8.0, 5.0, 14.0, 8.0, 6.0, 8.0, 2.0, 5.0, 8.0, 5.0, 5.0, 4.0, 4.0, 8.0, 9.0, 4.0, 4.0, 7.0, 10.0, 2.0, 4.0, 14.0, 2.0, 14.0, 4.0, 8.0, 4.0, 6.0, 15.0, 5.0, 13.0, 8.0, 3.0, 6.0, 5.0, 11.0, 4.0, 11.0, 8.0, 3.0, 6.0, 4.0, 2.0, 4.0, 13.0, 6.0, 7.0, 7.0, 6.0, 10.0, 10.0, 4.0, 4.0, 10.0, 7.0, 8.0, 15.0, 8.0, 11.0, 4.0, 12.0, 6.0, 15.0, 8.0, 9.0, 11.0, 15.0, 4.0, 4.0, 15.0, 10.0, 8.0, 4.0, 11.0, 8.0, 15.0, 3.0, 8.0, 8.0, 2.0, 2.0, 6.0, 7.0, 5.0, 11.0, 4.0, 7.0, 5.0, 5.0, 10.0, 4.0, 4.0, 15.0, 6.0, 5.0, 6.0, 3.0, 15.0, 6.0, 15.0, 7.0, 4.0, 4.0, 15.0, 10.0, 10.0, 5.0, 6.0, 8.0, 4.0, 5.0, 11.0, 5.0, 8.0, 7.0, 9.0, 15.0, 3.0, 5.0, 4.0, 15.0, 4.0, 7.0, 9.0, 3.0, 3.0, 8.0, 5.0, 4.0, 13.0, 5.0, 6.0, 6.0, 15.0, 3.0, 15.0, 9.0, 6.0, 9.0, 6.0, 3.0, 5.0, 15.0, 4.0, 13.0, 6.0, 15.0, 9.0, 14.0, 2.0, 5.0, 1.0, 10.0, 6.0, 7.0, 3.0, 10.0, 7.0, 9.0, 14.0, 11.0, 6.0, 8.0, 3.0, 13.0, 4.0, 5.0, 15.0, 13.0, 6.0, 2.0, 4.0, 6.0, 6.0, 15.0, 15.0, 3.0, 4.0, 14.0, 9.0, 8.0, 5.0, 15.0, 15.0, 8.0, 3.0, 7.0, 6.0, 15.0, 8.0, 11.0, 8.0, 15.0, 5.0, 4.0, 6.0, 5.0, 9.0, 15.0, 10.0, 13.0, 6.0, 6.0, 7.0, 4.0, 4.0, 7.0, 13.0, 8.0, 9.0, 5.0, 3.0, 5.0, 5.0, 6.0, 7.0, 6.0, 4.0, 3.0, 3.0, 6.0, 4.0, 6.0, 13.0, 8.0, 8.0, 3.0, 13.0, 4.0, 4.0, 4.0, 4.0, 8.0, 15.0, 3.0, 13.0, 7.0, 8.0, 11.0, 10.0, 7.0, 5.0, 7.0, 4.0, 8.0, 7.0, 12.0, 9.0, 3.0, 4.0, 8.0, 8.0, 6.0, 8.0, 3.0, 9.0, 5.0, 5.0, 4.0, 12.0, 4.0, 4.0, 6.0, 8.0, 10.0, 5.0, 6.0, 4.0, 6.0, 4.0, 15.0, 7.0, 3.0, 6.0, 15.0, 7.0, 8.0, 8.0, 5.0, 7.0, 3.0, 11.0, 3.0, 13.0, 5.0, 8.0, 8.0, 8.0, 3.0, 8.0, 5.0, 7.0, 3.0, 4.0, 2.0, 6.0, 15.0, 3.0, 8.0, 6.0, 7.0, 4.0, 5.0, 9.0, 7.0, 3.0, 3.0, 6.0, 4.0, 15.0, 9.0, 8.0, 8.0, 4.0, 6.0, 7.0, 8.0, 9.0, 6.0, 6.0, 8.0, 14.0, 13.0, 13.0, 3.0, 8.0, 9.0, 7.0, 4.0, 2.0, 5.0, 11.0, 4.0, 5.0, 11.0, 1.0, 8.0, 5.0, 5.0, 4.0, 5.0, 13.0, 10.0, 5.0, 4.0, 13.0, 4.0, 14.0, 7.0, 2.0, 3.0, 4.0, 11.0, 4.0, 7.0, 5.0, 4.0, 2.0, 7.0, 5.0, 6.0, 4.0, 3.0, 13.0, 4.0, 5.0, 10.0, 3.0, 15.0, 4.0, 3.0, 10.0, 1.0, 6.0, 13.0, 7.0, 9.0, 3.0, 15.0, 10.0, 15.0, 5.0, 15.0, 6.0, 7.0, 11.0, 3.0, 5.0, 9.0, 4.0, 4.0, 7.0, 10.0, 4.0, 3.0, 7.0, 9.0, 15.0, 7.0, 6.0, 11.0, 10.0, 7.0, 7.0, 3.0, 7.0, 10.0, 3.0, 10.0, 5.0, 9.0, 15.0, 4.0, 5.0, 5.0, 14.0, 14.0, 13.0, 13.0, 12.0, 15.0, 14.0, 13.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 13.0, 14.0, 19.0, 16.0, 12.0, 14.0, 14.0, 11.0, 13.0, 12.0, 12.0, 11.0, 13.0, 15.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 12.0, 12.0, 14.0, 17.0, 13.0, 10.0, 14.0, 13.0, 13.0, 12.0, 13.0, 10.0, 14.0, 14.0, 16.0, 16.0, 12.0, 12.0, 12.0, 13.0, 22.0, 13.0, 22.0, 12.0, 12.0, 12.0, 14.0, 16.0, 13.0, 16.0, 12.0, 13.0, 15.0, 12.0, 12.0, 13.0, 12.0, 19.0, 14.0, 14.0, 14.0, 14.0, 13.0, 14.0, 14.0, 14.0, 14.0, 13.0, 14.0, 14.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 14.0, 14.0, 15.0, 15.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 14.0, 13.0, 13.0, 14.0, 14.0, 14.0, 13.0, 14.0, 14.0, 14.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 14.0, 14.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 13.0, 14.0, 14.0, 14.0, 14.0, 13.0, 14.0, 14.0, 14.0, 14.0, 14.0, 17.0, 20.0, 19.0, 22.0, 15.0, 17.0, 18.0, 13.0, 17.0, 13.0, 16.0, 16.0, 14.0, 15.0, 15.0, 13.0, 13.0, 20.0, 17.0, 18.0, 13.0, 15.0, 12.0, 21.0, 20.0, 21.0, 13.0, 17.0, 15.0, 12.0, 23.0, 13.0, 13.0, 17.0, 15.0, 13.0, 21.0, 13.0, 18.0, 14.0, 18.0, 12.0, 15.0, 22.0, 12.0, 13.0, 19.0, 20.0, 13.0, 15.0, 19.0, 15.0, 20.0, 13.0, 14.0, 14.0, 13.0, 13.0, 20.0, 20.0, 13.0, 19.0, 13.0, 20.0, 19.0, 16.0, 19.0, 20.0, 17.0, 13.0, 20.0, 20.0, 20.0, 20.0, 15.0, 14.0, 19.0, 13.0, 20.0, 20.0, 12.0, 19.0, 17.0, 19.0, 11.0, 13.0, 15.0, 19.0, 20.0, 14.0, 20.0, 16.0, 20.0, 14.0, 13.0, 16.0, 20.0, 17.0, 19.0, 14.0, 19.0, 20.0, 13.0, 20.0, 20.0, 14.0, 19.0, 19.0, 13.0, 20.0, 17.0, 13.0, 14.0, 16.0, 13.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 20.0, 20.0, 26.0, 19.0, 20.0, 20.0, 20.0, 17.0, 16.0, 26.0, 19.0, 18.0, 20.0, 19.0, 26.0, 19.0, 20.0, 20.0, 19.0, 13.0, 14.0, 20.0, 18.0, 14.0, 20.0, 19.0, 14.0, 20.0, 12.0, 20.0, 13.0, 12.0, 13.0, 15.0, 11.0, 26.0, 20.0, 20.0, 13.0, 13.0, 13.0, 15.0, 14.0, 20.0, 14.0, 20.0, 14.0, 14.0, 14.0, 20.0, 15.0, 20.0, 20.0, 13.0, 20.0, 19.0, 21.0, 19.0, 20.0, 14.0, 13.0, 20.0, 20.0, 12.0, 14.0, 12.0, 20.0, 15.0, 13.0, 13.0, 20.0, 12.0, 12.0, 19.0, 14.0, 13.0, 13.0, 15.0, 20.0, 15.0, 14.0, 14.0, 13.0, 13.0, 19.0, 13.0, 14.0, 20.0, 19.0, 14.0, 14.0, 13.0, 18.0, 20.0, 21.0, 16.0, 19.0, 20.0, 20.0, 18.0, 15.0, 19.0, 14.0, 19.0, 19.0, 14.0, 13.0, 19.0, 14.0, 13.0, 20.0, 20.0, 20.0, 13.0, 15.0, 20.0, 20.0, 14.0, 20.0, 13.0, 14.0, 19.0, 19.0, 21.0, 20.0, 19.0, 21.0, 20.0, 19.0, 21.0, 20.0, 20.0, 21.0, 20.0, 20.0, 21.0, 13.0, 19.0, 21.0, 13.0, 20.0, 13.0, 19.0, 20.0, 13.0, 20.0, 14.0, 20.0, 22.0, 20.0, 20.0, 19.0, 13.0, 20.0, 12.0, 20.0, 19.0, 12.0, 19.0, 19.0, 19.0, 20.0, 20.0, 12.0, 19.0, 20.0, 18.0, 19.0, 20.0, 14.0, 20.0, 13.0, 17.0, 20.0, 19.0, 21.0, 20.0, 20.0, 16.0, 19.0, 20.0, 19.0, 20.0, 13.0, 13.0, 13.0, 20.0, 20.0, 13.0, 19.0, 19.0, 13.0, 19.0, 13.0, 20.0, 13.0, 19.0, 18.0, 13.0, 19.0, 12.0, 20.0, 14.0, 20.0, 20.0, 13.0, 20.0, 15.0, 20.0, 20.0, 14.0, 20.0, 20.0, 14.0, 20.0, 20.0, 18.0, 20.0, 20.0, 13.0, 15.0, 13.0, 20.0, 14.0, 13.0, 13.0, 20.0, 14.0, 13.0, 13.0, 13.0, 14.0, 20.0, 14.0, 20.0, 20.0, 14.0, 20.0, 12.0, 19.0, 13.0, 13.0, 14.0, 11.0, 14.0, 20.0, 19.0, 14.0, 13.0, 13.0, 20.0, 13.0, 20.0, 20.0, 15.0, 14.0, 15.0, 13.0, 20.0, 12.0, 13.0, 12.0, 14.0, 12.0, 12.0, 15.0, 14.0, 15.0, 16.0, 15.0, 16.0, 14.0, 14.0, 16.0, 16.0, 16.0, 13.0, 14.0, 15.0, 15.0, 15.0, 15.0, 16.0, 15.0, 14.0, 15.0, 14.0, 15.0, 14.0, 15.0, 15.0, 15.0, 16.0, 14.0, 15.0, 9.0, 13.0, 13.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 8.0, 9.0, 9.0, 12.0, 9.0, 12.0, 9.0, 11.0, 13.0, 9.0, 12.0, 11.0, 7.0, 13.0, 12.0, 23.0, 12.0, 22.0, 12.0, 22.0, 12.0, 11.0, 12.0, 12.0, 14.0, 15.0, 11.0, 15.0, 12.0, 20.0, 18.0, 12.0, 21.0, 22.0, 12.0, 18.0, 19.0, 15.0, 19.0, 15.0, 19.0, 13.0, 15.0, 15.0, 15.0, 12.0, 15.0, 17.0, 14.0, 15.0, 15.0, 16.0, 20.0, 20.0, 11.0, 17.0, 21.0, 22.0, 21.0, 21.0, 14.0, 20.0, 18.0, 14.0, 11.0, 12.0, 14.0, 16.0, 17.0, 18.0, 16.0, 11.0, 16.0, 22.0, 17.0, 21.0, 12.0, 21.0, 21.0, 21.0, 17.0, 16.0, 12.0, 18.0, 17.0, 16.0, 12.0, 22.0, 15.0, 17.0, 21.0, 21.0, 21.0, 21.0, 11.0, 21.0, 21.0, 21.0, 21.0, 11.0, 17.0, 21.0, 15.0, 12.0, 23.0, 19.0, 12.0, 23.0, 11.0, 22.0, 22.0, 12.0, 21.0, 21.0, 14.0, 21.0, 11.0, 12.0, 12.0, 20.0, 11.0, 20.0, 21.0, 15.0, 20.0, 21.0, 11.0, 12.0, 20.0, 21.0, 22.0, 20.0, 11.0, 21.0, 20.0, 11.0, 21.0, 22.0, 11.0, 21.0, 22.0, 11.0, 21.0, 22.0, 12.0, 21.0, 23.0, 21.0, 12.0, 12.0, 17.0, 21.0, 23.0, 17.0, 21.0, 21.0, 18.0, 21.0, 23.0, 11.0, 21.0, 22.0, 22.0, 15.0, 22.0, 22.0, 22.0, 21.0, 16.0, 21.0, 20.0, 20.0, 12.0, 12.0, 22.0, 16.0, 13.0, 22.0, 21.0, 12.0, 14.0, 22.0, 12.0, 20.0, 12.0, 12.0, 23.0, 11.0, 20.0, 22.0, 22.0, 21.0, 21.0, 22.0, 23.0, 11.0, 12.0, 20.0, 11.0, 14.0, 21.0, 12.0, 22.0, 21.0, 22.0, 21.0, 20.0, 11.0, 21.0, 13.0, 19.0, 22.0, 11.0, 22.0, 12.0, 22.0, 16.0, 12.0, 16.0, 11.0, 16.0, 18.0, 16.0, 22.0, 22.0, 13.0, 22.0, 11.0, 22.0, 14.0, 21.0, 23.0, 12.0, 16.0, 14.0, 22.0, 17.0, 19.0, 20.0, 22.0, 22.0, 21.0, 20.0, 21.0, 16.0, 23.0, 14.0, 21.0, 14.0, 22.0, 16.0, 20.0, 21.0, 22.0, 12.0, 16.0, 22.0, 22.0, 22.0, 22.0, 23.0, 14.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 22.0, 16.0, 22.0, 16.0, 23.0, 16.0, 22.0, 20.0, 20.0, 12.0, 16.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 23.0, 22.0, 21.0, 16.0, 21.0, 14.0, 22.0, 16.0, 22.0, 16.0, 23.0, 20.0, 22.0, 21.0, 22.0, 18.0, 16.0, 22.0, 22.0, 22.0, 16.0, 22.0, 22.0, 21.0, 12.0, 20.0, 22.0, 12.0, 20.0, 14.0, 22.0, 17.0, 20.0, 12.0, 21.0, 17.0, 21.0, 21.0, 11.0, 13.0, 13.0, 13.0, 14.0, 16.0, 9.0, 9.0, 10.0, 13.0, 17.0, 16.0, 20.0, 18.0, 13.0, 17.0, 17.0, 20.0, 16.0, 17.0, 20.0, 22.0, 16.0, 13.0, 11.0, 20.0, 20.0, 12.0, 11.0, 14.0, 13.0, 20.0, 12.0, 11.0, 17.0, 15.0, 16.0, 16.0, 21.0, 20.0, 24.0, 18.0, 17.0, 16.0, 20.0, 25.0, 10.0, 16.0, 14.0, 17.0, 13.0, 20.0, 19.0, 24.0, 16.0, 16.0, 13.0, 18.0, 22.0, 21.0, 10.0, 13.0, 19.0, 22.0, 22.0, 16.0, 13.0, 22.0, 13.0, 24.0, 25.0, 22.0, 21.0, 22.0, 14.0, 15.0, 22.0, 22.0, 18.0, 20.0, 19.0, 13.0, 15.0, 15.0, 21.0, 22.0, 16.0, 13.0, 19.0, 15.0, 22.0, 10.0, 16.0, 13.0, 20.0, 21.0, 12.0, 16.0, 11.0, 13.0, 22.0, 13.0, 16.0, 16.0, 16.0, 16.0, 18.0, 24.0, 16.0, 20.0, 16.0, 13.0, 20.0, 18.0, 22.0, 10.0, 16.0, 14.0, 22.0, 22.0, 22.0, 22.0, 22.0, 20.0, 22.0, 24.0, 22.0, 19.0, 24.0, 20.0, 17.0, 22.0, 19.0, 22.0, 11.0, 16.0, 18.0, 22.0, 24.0, 22.0, 11.0, 15.0, 18.0, 22.0, 16.0, 22.0, 16.0, 16.0, 17.0, 22.0, 21.0, 13.0, 17.0, 12.0, 14.0, 22.0, 13.0, 13.0, 15.0, 13.0, 22.0, 22.0, 24.0, 24.0, 16.0, 10.0, 22.0, 22.0, 11.0, 17.0, 22.0, 22.0, 13.0, 13.0, 18.0, 24.0, 20.0, 22.0, 13.0, 13.0, 20.0, 18.0, 24.0, 17.0, 16.0, 17.0, 18.0, 22.0, 11.0, 13.0, 16.0, 17.0, 22.0, 16.0, 13.0, 17.0, 16.0, 16.0, 20.0, 22.0, 16.0, 16.0, 13.0, 16.0, 13.0, 20.0, 22.0, 16.0, 14.0, 16.0, 19.0, 20.0, 21.0, 16.0, 18.0, 15.0, 17.0, 21.0, 16.0, 16.0, 21.0, 17.0, 14.0, 22.0, 16.0, 16.0, 21.0, 20.0, 13.0, 11.0, 13.0, 10.0, 20.0, 13.0, 24.0, 11.0, 16.0, 13.0, 13.0, 24.0, 22.0, 16.0, 16.0, 21.0, 20.0, 13.0, 22.0, 22.0, 16.0, 19.0, 15.0, 17.0, 22.0, 24.0, 16.0, 15.0, 15.0, 15.0, 17.0, 24.0, 13.0, 22.0, 17.0, 24.0, 22.0, 18.0, 22.0, 11.0, 13.0, 11.0, 15.0, 22.0, 16.0, 20.0, 13.0, 17.0, 13.0, 11.0, 18.0, 13.0, 16.0, 17.0, 13.0, 18.0, 20.0, 24.0, 11.0, 14.0, 20.0, 22.0, 13.0, 16.0, 15.0, 13.0, 22.0, 16.0, 22.0, 21.0, 15.0, 22.0, 25.0, 16.0, 20.0, 25.0, 15.0, 22.0, 14.0, 13.0, 15.0, 17.0, 22.0, 11.0, 15.0, 14.0, 17.0, 18.0, 12.0, 20.0, 16.0, 15.0, 13.0, 18.0, 21.0, 16.0, 13.0, 16.0, 16.0, 13.0, 22.0, 13.0, 16.0, 16.0, 16.0, 16.0, 15.0, 10.0, 16.0, 16.0, 17.0, 16.0, 13.0, 16.0, 10.0, 20.0, 13.0, 17.0, 20.0, 15.0, 13.0, 22.0, 24.0, 22.0, 24.0, 17.0, 16.0, 10.0, 16.0, 13.0, 13.0, 19.0, 22.0, 13.0, 16.0, 24.0, 11.0, 17.0, 16.0, 11.0, 13.0, 13.0, 16.0, 25.0, 17.0, 11.0, 16.0, 13.0, 14.0, 20.0, 16.0, 22.0, 16.0, 24.0, 20.0, 21.0, 22.0, 16.0, 14.0, 11.0, 24.0, 16.0, 20.0, 22.0, 16.0, 22.0, 22.0, 24.0, 15.0, 22.0, 20.0, 22.0, 22.0, 16.0, 24.0, 16.0, 22.0, 22.0, 17.0, 13.0, 16.0, 24.0, 21.0, 17.0, 22.0, 22.0, 17.0, 21.0, 22.0, 13.0, 19.0, 22.0, 10.0, 11.0, 22.0, 22.0, 13.0, 22.0, 13.0, 13.0, 22.0, 22.0, 13.0, 16.0, 13.0, 19.0, 11.0, 11.0, 22.0, 16.0, 13.0, 13.0, 22.0, 22.0, 16.0, 16.0, 17.0, 18.0, 19.0, 21.0, 22.0, 10.0, 16.0, 14.0, 18.0, 16.0, 18.0, 21.0, 21.0, 11.0, 16.0, 17.0, 21.0, 22.0, 22.0, 22.0, 16.0, 14.0, 13.0, 22.0, 22.0, 22.0, 22.0, 14.0, 17.0, 13.0, 13.0, 22.0, 13.0, 20.0, 21.0, 22.0, 21.0, 14.0, 11.0, 17.0, 21.0, 22.0, 18.0, 13.0, 13.0, 10.0, 22.0, 12.0, 16.0, 18.0, 13.0, 13.0, 13.0, 14.0, 11.0, 22.0, 17.0, 15.0, 13.0, 13.0, 13.0, 10.0, 22.0, 10.0, 15.0, 13.0, 13.0, 17.0, 19.0, 22.0, 16.0, 16.0, 15.0, 16.0, 18.0, 19.0, 22.0, 16.0, 16.0, 15.0, 20.0, 19.0, 22.0, 16.0, 24.0, 15.0, 22.0, 22.0, 25.0, 16.0, 16.0, 16.0, 22.0, 11.0, 16.0, 18.0, 16.0, 16.0, 18.0, 13.0, 22.0, 17.0, 15.0, 18.0, 24.0, 16.0, 13.0, 13.0, 15.0, 22.0, 17.0, 21.0, 22.0, 13.0, 14.0, 15.0, 16.0, 22.0, 21.0, 15.0, 16.0, 21.0, 22.0, 22.0, 10.0, 16.0, 22.0, 10.0, 13.0, 22.0, 11.0, 25.0, 13.0, 17.0, 11.0, 14.0, 22.0, 16.0, 22.0, 24.0, 22.0, 11.0, 17.0, 24.0, 13.0, 25.0, 12.0, 16.0, 16.0, 11.0, 13.0, 16.0, 16.0, 17.0, 16.0, 25.0, 22.0, 25.0, 11.0, 13.0, 17.0, 16.0, 22.0, 22.0, 24.0, 16.0, 18.0, 22.0, 13.0, 22.0, 15.0, 25.0, 12.0, 17.0, 22.0, 22.0, 16.0, 19.0, 16.0, 16.0, 18.0, 20.0, 22.0, 24.0, 16.0, 19.0, 14.0, 10.0, 16.0, 16.0, 14.0, 18.0, 16.0, 16.0, 22.0, 22.0, 25.0, 16.0, 17.0, 13.0, 14.0, 20.0, 11.0, 24.0, 22.0, 13.0, 16.0, 16.0, 22.0, 13.0, 25.0, 16.0, 21.0, 22.0, 25.0, 24.0, 18.0, 21.0, 22.0, 13.0, 24.0, 16.0, 16.0, 17.0, 16.0, 22.0, 24.0, 11.0, 16.0, 16.0, 18.0, 22.0, 22.0, 24.0, 11.0, 11.0, 16.0, 22.0, 22.0, 22.0, 16.0, 13.0, 17.0, 22.0, 13.0, 16.0, 16.0, 20.0, 13.0, 18.0, 16.0, 17.0, 13.0, 20.0, 22.0, 18.0, 16.0, 17.0, 22.0, 22.0, 22.0, 25.0, 11.0, 22.0, 22.0, 15.0, 13.0, 11.0, 20.0, 21.0, 13.0, 12.0, 22.0, 24.0, 12.0, 11.0, 17.0, 22.0, 22.0, 24.0, 12.0, 20.0, 22.0, 16.0, 22.0, 24.0, 10.0, 22.0, 22.0, 21.0, 15.0, 18.0, 11.0, 20.0, 22.0, 22.0, 16.0, 15.0, 18.0, 22.0, 22.0, 24.0, 13.0, 17.0, 20.0, 22.0, 17.0, 22.0, 13.0, 20.0, 18.0, 22.0, 13.0, 22.0, 19.0, 21.0, 10.0, 13.0, 16.0, 22.0, 10.0, 11.0, 16.0, 20.0, 16.0, 17.0, 13.0, 13.0, 21.0, 22.0, 11.0, 22.0, 17.0, 13.0, 21.0, 22.0, 18.0, 14.0, 17.0, 13.0, 13.0, 20.0, 22.0, 18.0, 22.0, 13.0, 17.0, 17.0, 20.0, 22.0, 22.0, 16.0, 16.0, 16.0, 16.0, 16.0, 22.0, 13.0, 18.0, 16.0, 16.0, 16.0, 16.0, 13.0, 18.0, 22.0, 22.0, 16.0, 22.0, 22.0, 22.0, 22.0, 17.0, 18.0, 14.0, 10.0, 22.0, 22.0, 17.0, 22.0, 22.0, 12.0, 19.0, 22.0, 22.0, 12.0, 24.0, 16.0, 16.0, 19.0, 22.0, 13.0, 18.0, 17.0, 16.0, 24.0, 13.0, 18.0, 21.0, 16.0, 13.0, 22.0, 14.0, 18.0, 14.0, 14.0, 13.0, 24.0, 25.0, 13.0, 20.0, 18.0, 14.0, 22.0, 25.0, 16.0, 13.0, 20.0, 14.0, 25.0, 11.0, 16.0, 17.0, 24.0, 11.0, 16.0, 14.0, 15.0, 18.0, 22.0, 10.0, 22.0, 16.0, 13.0, 19.0, 16.0, 11.0, 13.0, 22.0, 24.0, 24.0, 16.0, 13.0, 21.0, 22.0, 24.0, 16.0, 13.0, 18.0, 16.0, 17.0, 16.0, 22.0, 16.0, 19.0, 21.0, 16.0, 22.0, 22.0, 25.0, 16.0, 16.0, 21.0, 18.0, 14.0, 20.0, 13.0, 14.0, 22.0, 25.0, 22.0, 22.0, 15.0, 16.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 15.0, 13.0, 16.0, 15.0, 15.0, 15.0, 16.0, 16.0, 15.0, 15.0, 16.0, 15.0, 16.0, 16.0, 15.0, 15.0, 15.0, 16.0, 15.0, 16.0, 16.0, 16.0, 16.0, 17.0, 16.0, 16.0, 13.0, 15.0, 14.0, 14.0, 14.0, 14.0, 15.0, 16.0, 16.0, 16.0, 16.0, 15.0, 16.0, 16.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 14.0, 18.0, 13.0, 17.0, 14.0, 16.0, 14.0, 15.0, 14.0, 13.0, 15.0, 14.0, 15.0, 14.0, 20.0, 16.0, 16.0, 15.0, 21.0, 14.0, 14.0, 21.0, 23.0, 17.0, 23.0, 23.0, 21.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 20.0, 14.0, 20.0, 23.0, 23.0, 22.0, 21.0, 21.0, 21.0, 16.0, 21.0, 23.0, 17.0, 16.0, 18.0, 13.0, 13.0, 13.0, 13.0, 17.0, 16.0, 22.0, 13.0, 14.0, 13.0, 20.0, 23.0, 13.0, 20.0, 22.0, 15.0, 22.0, 20.0, 13.0, 15.0, 16.0, 15.0, 16.0, 11.0, 9.0, 12.0, 11.0, 9.0, 15.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 21.0, 13.0, 13.0, 13.0, 18.0, 15.0, 21.0, 13.0, 19.0, 14.0, 13.0, 13.0, 11.0, 10.0, 12.0, 12.0, 14.0, 11.0, 12.0, 10.0, 14.0, 10.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 14.0, 11.0, 14.0, 9.0, 14.0, 14.0, 12.0, 10.0, 14.0, 12.0, 10.0, 14.0, 12.0, 12.0, 14.0, 14.0, 10.0, 11.0, 14.0, 11.0, 14.0, 14.0, 12.0, 12.0, 12.0, 10.0, 14.0, 14.0, 10.0, 14.0, 12.0, 14.0, 14.0, 9.0, 14.0, 14.0, 13.0, 9.0, 14.0, 12.0, 10.0, 14.0, 12.0, 11.0, 12.0, 12.0, 14.0, 12.0, 14.0, 11.0, 14.0, 9.0, 10.0, 14.0, 9.0, 10.0, 10.0, 14.0, 11.0, 10.0, 14.0, 11.0, 10.0, 14.0, 10.0, 10.0, 9.0, 9.0, 10.0, 11.0, 10.0, 10.0, 14.0, 10.0, 14.0, 11.0, 11.0, 12.0, 14.0, 11.0, 15.0, 10.0, 14.0, 11.0, 14.0, 9.0, 14.0, 11.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 14.0, 11.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 12.0, 14.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 14.0, 9.0, 11.0, 10.0, 10.0, 10.0, 14.0, 11.0, 15.0, 14.0, 14.0, 15.0, 14.0, 12.0, 11.0, 11.0, 10.0, 12.0, 11.0, 10.0, 11.0, 14.0, 14.0, 12.0, 10.0, 12.0, 14.0, 10.0, 15.0, 14.0, 9.0, 11.0, 14.0, 12.0, 10.0, 12.0, 12.0, 12.0, 11.0, 15.0, 14.0, 9.0, 10.0, 11.0, 14.0, 14.0, 10.0, 15.0, 14.0, 14.0, 15.0, 14.0, 11.0, 12.0, 14.0, 14.0, 11.0, 12.0, 14.0, 10.0, 12.0, 14.0, 14.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 12.0, 11.0, 14.0, 15.0, 14.0, 10.0, 10.0, 11.0, 14.0, 10.0, 11.0, 14.0, 10.0, 15.0, 14.0, 11.0, 10.0, 12.0, 14.0, 12.0, 14.0, 10.0, 10.0, 15.0, 14.0, 10.0, 15.0, 14.0, 10.0, 15.0, 14.0, 10.0, 10.0, 11.0, 15.0, 12.0, 14.0, 11.0, 14.0, 14.0, 14.0, 14.0, 14.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 12.0, 15.0, 14.0, 14.0, 11.0, 10.0, 12.0, 11.0, 12.0, 14.0, 14.0, 15.0, 12.0, 12.0, 15.0, 14.0, 9.0, 14.0, 14.0, 14.0, 15.0, 14.0, 12.0, 14.0, 14.0, 14.0, 11.0, 14.0, 12.0, 12.0, 11.0, 14.0, 14.0, 10.0, 15.0, 14.0, 9.0, 12.0, 14.0, 15.0, 12.0, 14.0, 11.0, 14.0, 14.0, 15.0, 14.0, 14.0, 10.0, 15.0, 10.0, 10.0, 11.0, 14.0, 10.0, 15.0, 14.0, 10.0, 10.0, 14.0, 11.0, 10.0, 14.0, 11.0, 15.0, 14.0, 10.0, 15.0, 14.0, 11.0, 12.0, 10.0, 14.0, 12.0, 14.0, 14.0, 12.0, 14.0, 11.0, 10.0, 14.0, 12.0, 15.0, 14.0, 14.0, 12.0, 14.0, 14.0, 11.0, 14.0, 10.0, 10.0, 14.0, 14.0, 14.0, 14.0, 9.0, 11.0, 14.0, 14.0, 15.0, 14.0, 9.0, 11.0, 10.0, 12.0, 14.0, 11.0, 12.0, 14.0, 10.0, 14.0, 12.0, 10.0, 14.0, 14.0, 14.0, 12.0, 11.0, 14.0, 14.0, 11.0, 14.0, 14.0, 11.0, 14.0, 14.0, 14.0, 12.0, 9.0, 10.0, 14.0, 12.0, 14.0, 14.0, 10.0, 14.0, 14.0, 12.0, 14.0, 14.0, 9.0, 12.0, 14.0, 9.0, 10.0, 14.0, 12.0, 14.0, 11.0, 11.0, 9.0, 14.0, 12.0, 11.0, 14.0, 14.0, 14.0, 14.0, 9.0, 14.0, 14.0, 9.0, 11.0, 10.0, 12.0, 10.0, 10.0, 14.0, 10.0, 10.0, 10.0, 14.0, 11.0, 11.0, 10.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 23.0, 17.0, 23.0, 23.0, 23.0, 26.0, 23.0, 22.0, 26.0, 26.0, 2.0, 29.0, 22.0, 25.0, 23.0, 26.0, 23.0, 23.0, 23.0, 23.0, 21.0, 21.0, 29.0, 24.0, 20.0, 22.0, 21.0, 19.0, 17.0, 22.0, 17.0, 20.0, 29.0, 17.0, 17.0, 16.0, 25.0, 20.0, 23.0, 20.0, 16.0, 20.0, 29.0, 22.0, 29.0, 20.0, 29.0, 21.0, 29.0, 23.0, 29.0, 18.0, 23.0, 20.0, 29.0, 20.0, 19.0, 22.0, 29.0, 21.0, 29.0, 19.0, 29.0, 20.0, 29.0, 20.0, 29.0, 18.0, 20.0, 21.0, 19.0, 17.0, 20.0, 16.0, 24.0, 18.0, 21.0, 16.0, 26.0, 15.0, 20.0, 14.0, 17.0, 23.0, 21.0, 20.0, 19.0, 24.0, 26.0, 17.0, 24.0, 26.0, 24.0, 24.0, 24.0, 24.0, 22.0, 19.0, 24.0, 22.0, 24.0, 22.0, 24.0, 22.0, 20.0, 24.0, 24.0, 15.0, 22.0, 20.0, 24.0, 24.0, 20.0, 24.0, 17.0, 24.0, 22.0, 22.0, 18.0, 24.0, 24.0, 24.0, 22.0, 24.0, 23.0, 24.0, 24.0, 24.0, 23.0, 24.0, 24.0, 21.0, 24.0, 17.0, 22.0, 18.0, 17.0, 14.0, 22.0, 22.0, 17.0, 23.0, 24.0, 24.0, 24.0, 21.0, 22.0, 23.0, 22.0, 22.0, 23.0, 23.0, 23.0, 22.0, 19.0, 16.0, 17.0, 23.0, 23.0, 23.0, 26.0, 24.0, 23.0, 17.0, 17.0, 26.0, 21.0, 23.0, 25.0, 21.0, 17.0, 23.0, 21.0, 24.0, 23.0, 26.0, 20.0, 23.0, 23.0, 23.0, 22.0, 20.0, 21.0, 24.0, 22.0, 22.0, 26.0, 21.0, 27.0, 24.0, 23.0, 22.0, 21.0, 17.0, 20.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 6.0, 4.0, 8.0, 4.0, 5.0, 9.0, 3.0, 3.0, 6.0, 9.0, 4.0, 7.0, 5.0, 3.0, 6.0, 8.0, 10.0, 10.0, 8.0, 3.0, 9.0, 4.0, 8.0, 5.0, 7.0, 6.0, 8.0, 4.0, 9.0, 6.0, 4.0, 7.0, 2.0, 0.0, 4.0, 8.0, 6.0, 5.0, 2.0, 7.0, 3.0, 5.0, 4.0, 4.0, 7.0, 6.0, 5.0, 9.0, 3.0, 5.0, 3.0, 3.0, 5.0, 9.0, 4.0, 4.0, 3.0, 6.0, 9.0, 9.0, 5.0, 3.0, 3.0, 3.0, 5.0, 4.0, 8.0, 8.0, 5.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 7.0, 11.0, 10.0, 15.0, 10.0, 14.0, 14.0, 15.0, 14.0, 14.0, 15.0, 13.0, 13.0, 15.0, 9.0, 8.0, 6.0, 5.0, 4.0, 9.0, 4.0, 4.0, 9.0, 7.0, 18.0, 16.0, 20.0, 15.0, 23.0, 18.0, 19.0, 16.0, 21.0, 20.0, 24.0, 19.0, 23.0, 15.0, 21.0, 16.0, 23.0, 15.0, 23.0, 22.0, 21.0, 17.0, 23.0, 23.0, 20.0, 15.0, 17.0, 23.0, 16.0, 17.0, 20.0, 23.0, 17.0, 17.0, 23.0, 19.0, 23.0, 21.0, 19.0, 17.0, 20.0, 22.0, 23.0, 22.0, 15.0, 19.0, 23.0, 21.0, 23.0, 23.0, 21.0, 23.0, 15.0, 21.0, 23.0, 16.0, 20.0, 23.0, 15.0, 21.0, 13.0, 23.0, 17.0, 20.0, 20.0, 15.0, 23.0, 23.0, 20.0, 21.0, 22.0, 16.0, 24.0, 21.0, 16.0, 21.0, 20.0, 14.0, 17.0, 21.0, 21.0, 16.0, 23.0, 15.0, 16.0, 20.0, 23.0, 23.0, 15.0, 20.0, 22.0, 14.0, 21.0, 15.0, 16.0, 22.0, 23.0, 15.0, 21.0, 21.0, 20.0, 17.0, 21.0, 14.0, 22.0, 23.0, 17.0, 22.0, 19.0, 23.0, 21.0, 22.0, 20.0, 23.0, 21.0, 21.0, 20.0, 21.0, 21.0, 20.0, 23.0, 15.0, 23.0, 21.0, 21.0, 20.0, 21.0, 15.0, 22.0, 20.0, 15.0, 21.0, 21.0, 21.0, 21.0, 16.0, 22.0, 13.0, 21.0, 20.0, 22.0, 24.0, 20.0, 20.0, 23.0, 16.0, 21.0, 19.0, 23.0, 23.0, 20.0, 21.0, 21.0, 15.0, 22.0, 20.0, 20.0, 24.0, 25.0, 21.0, 21.0, 21.0, 20.0, 19.0, 25.0, 21.0, 20.0, 21.0, 22.0, 24.0, 21.0, 15.0, 17.0, 24.0, 15.0, 23.0, 21.0, 20.0, 21.0, 23.0, 15.0, 22.0, 20.0, 20.0, 24.0, 15.0, 21.0, 23.0, 21.0, 21.0, 17.0, 21.0, 23.0, 21.0, 21.0, 23.0, 13.0, 20.0, 23.0, 21.0, 20.0, 23.0, 18.0, 23.0, 22.0, 20.0, 21.0, 22.0, 26.0, 23.0, 20.0, 22.0, 23.0, 13.0, 21.0, 22.0, 14.0, 13.0, 21.0, 22.0, 26.0, 21.0, 21.0, 20.0, 26.0, 21.0, 21.0, 26.0, 20.0, 20.0, 21.0, 26.0, 23.0, 21.0, 21.0, 22.0, 24.0, 23.0, 21.0, 20.0, 14.0, 21.0, 21.0, 23.0, 24.0, 26.0, 21.0, 21.0, 21.0, 26.0, 21.0, 21.0, 23.0, 21.0, 20.0, 23.0, 23.0, 21.0, 20.0, 26.0, 23.0, 20.0, 26.0, 20.0, 21.0, 22.0, 25.0, 22.0, 26.0, 17.0, 20.0, 22.0, 26.0, 21.0, 21.0, 23.0, 20.0, 15.0, 20.0, 23.0, 20.0, 21.0, 23.0, 16.0, 15.0, 20.0, 24.0, 23.0, 23.0, 22.0, 21.0, 23.0, 20.0, 21.0, 23.0, 25.0, 26.0, 23.0, 21.0, 23.0, 21.0, 21.0, 20.0, 23.0, 21.0, 21.0, 23.0, 25.0, 23.0, 22.0, 21.0, 22.0, 21.0, 22.0, 14.0, 24.0, 21.0, 23.0, 21.0, 20.0, 17.0, 15.0, 20.0, 22.0, 13.0, 21.0, 22.0, 24.0, 23.0, 16.0, 23.0, 23.0, 25.0, 19.0, 21.0, 23.0, 26.0, 17.0, 20.0, 21.0, 14.0, 15.0, 20.0, 26.0, 20.0, 21.0, 20.0, 20.0, 25.0, 20.0, 20.0, 23.0, 26.0, 26.0, 21.0, 20.0, 26.0, 21.0, 20.0, 23.0, 26.0, 15.0, 21.0, 17.0, 21.0, 21.0, 23.0, 21.0, 20.0, 21.0, 15.0, 23.0, 20.0, 20.0, 20.0, 22.0, 20.0, 21.0, 14.0, 23.0, 15.0, 19.0, 20.0, 23.0, 21.0, 21.0, 23.0, 17.0, 23.0, 21.0, 17.0, 24.0, 20.0, 20.0, 17.0, 20.0, 15.0, 17.0, 20.0, 21.0, 15.0, 20.0, 16.0, 18.0, 19.0, 21.0, 25.0, 23.0, 21.0, 21.0, 23.0, 17.0, 17.0, 20.0, 25.0, 20.0, 15.0, 23.0, 16.0, 22.0, 23.0, 20.0, 21.0, 20.0, 21.0, 20.0, 26.0, 21.0, 15.0, 26.0, 22.0, 18.0, 24.0, 18.0, 21.0, 18.0, 20.0, 24.0, 26.0, 21.0, 14.0, 24.0, 18.0, 21.0, 17.0, 22.0, 14.0, 21.0, 23.0, 21.0, 20.0, 22.0, 17.0, 17.0, 22.0, 24.0, 16.0, 17.0, 20.0, 24.0, 16.0, 17.0, 18.0, 21.0, 20.0, 18.0, 20.0, 24.0, 22.0, 17.0, 21.0, 14.0, 20.0, 17.0, 22.0, 15.0, 23.0, 20.0, 15.0, 25.0, 20.0, 23.0, 17.0, 20.0, 20.0, 13.0, 22.0, 24.0, 19.0, 21.0, 21.0, 20.0, 20.0, 22.0, 23.0, 1.0, 1.0, 0.0, 0.0, 14.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 12.0, 12.0, 1.0, 1.0, 1.0, 0.0, 13.0, 14.0, 14.0, 12.0, 13.0, 13.0, 13.0, 14.0, 13.0, 14.0, 13.0, 13.0, 16.0, 17.0, 14.0, 14.0, 16.0, 13.0, 13.0, 15.0, 13.0, 13.0, 16.0, 11.0, 16.0, 11.0, 13.0, 13.0, 13.0, 15.0, 17.0, 10.0, 12.0, 13.0, 15.0, 15.0, 13.0, 11.0, 12.0, 12.0, 14.0, 15.0, 16.0, 16.0, 14.0, 24.0, 14.0, 12.0, 11.0, 12.0, 21.0, 15.0, 18.0, 17.0, 17.0, 11.0, 12.0, 14.0, 12.0, 14.0, 14.0, 18.0, 14.0, 17.0, 13.0, 14.0, 11.0, 18.0, 14.0, 12.0, 11.0, 17.0, 15.0, 13.0, 15.0, 15.0, 13.0, 12.0, 17.0, 15.0, 14.0, 13.0, 13.0, 12.0, 14.0, 18.0, 13.0, 16.0, 16.0, 12.0, 12.0, 13.0, 15.0, 17.0, 14.0, 14.0, 10.0, 13.0, 13.0, 14.0, 13.0, 22.0, 11.0, 14.0, 14.0, 14.0, 17.0, 13.0, 12.0, 12.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 13.0, 14.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 13.0, 12.0, 12.0, 16.0, 14.0, 12.0, 14.0, 12.0, 14.0, 12.0, 13.0, 12.0, 12.0, 11.0, 12.0, 10.0, 11.0, 13.0, 12.0, 13.0, 13.0, 16.0, 13.0, 13.0, 15.0, 15.0, 13.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 15.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 13.0, 25.0, 13.0, 14.0, 12.0, 12.0, 13.0, 12.0, 13.0, 13.0, 25.0, 13.0, 25.0, 13.0, 25.0, 14.0, 14.0, 12.0, 14.0, 25.0, 14.0, 14.0, 12.0, 16.0, 14.0, 15.0, 15.0, 12.0, 12.0, 13.0, 12.0, 17.0, 16.0, 17.0, 13.0, 12.0, 13.0, 12.0, 12.0, 13.0, 15.0, 16.0, 12.0, 15.0, 10.0, 17.0, 15.0, 14.0, 16.0, 12.0, 13.0, 12.0, 13.0, 15.0, 15.0, 15.0, 11.0, 14.0, 15.0, 15.0, 15.0, 12.0, 11.0, 16.0, 16.0, 13.0, 12.0, 13.0, 16.0, 11.0, 12.0, 11.0, 12.0, 14.0, 13.0, 15.0, 13.0, 11.0, 12.0, 11.0, 12.0, 15.0, 16.0, 10.0, 15.0, 14.0, 13.0, 12.0, 12.0, 12.0, 12.0, 13.0, 13.0, 15.0, 13.0, 15.0, 12.0, 15.0, 12.0, 12.0, 13.0, 11.0, 14.0, 15.0, 12.0, 15.0, 15.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 16.0, 15.0, 13.0, 12.0, 13.0, 12.0, 12.0, 13.0, 12.0, 12.0, 12.0, 13.0, 15.0, 13.0, 15.0, 12.0, 14.0, 13.0, 15.0, 12.0, 15.0, 12.0, 12.0, 13.0, 15.0, 14.0, 15.0, 12.0, 15.0, 14.0, 15.0, 14.0, 12.0, 16.0, 12.0, 13.0, 15.0, 12.0, 14.0, 13.0, 15.0, 13.0, 15.0, 14.0, 15.0, 14.0, 12.0, 14.0, 15.0, 14.0, 16.0, 13.0, 12.0, 14.0, 12.0, 14.0, 12.0, 12.0, 13.0, 15.0, 15.0, 14.0, 13.0, 14.0, 11.0, 14.0, 12.0, 14.0, 13.0, 14.0, 12.0, 14.0, 13.0, 14.0, 13.0, 14.0, 13.0, 13.0, 13.0, 14.0, 14.0, 15.0, 16.0, 13.0, 12.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 14.0, 13.0, 14.0, 12.0, 13.0, 12.0, 14.0, 12.0, 14.0, 12.0, 12.0, 13.0, 14.0, 15.0, 15.0, 14.0, 14.0, 13.0, 19.0, 14.0, 19.0, 12.0, 14.0, 14.0, 14.0, 13.0, 14.0, 19.0, 14.0, 19.0, 13.0, 14.0, 17.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 14.0, 16.0, 15.0, 14.0, 13.0, 14.0, 15.0, 14.0, 15.0, 18.0, 16.0, 16.0, 18.0, 14.0, 17.0, 14.0, 15.0, 14.0, 14.0, 16.0, 14.0, 13.0, 19.0, 14.0, 19.0, 14.0, 14.0, 15.0, 17.0, 17.0, 14.0, 14.0, 14.0, 19.0, 14.0, 15.0, 14.0, 17.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 14.0, 15.0, 19.0, 18.0, 17.0, 14.0, 15.0, 15.0, 14.0, 15.0, 14.0, 15.0, 15.0, 15.0, 14.0, 15.0, 15.0, 14.0, 17.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 14.0, 14.0, 19.0, 19.0, 14.0, 15.0, 14.0, 16.0, 15.0, 15.0, 15.0, 18.0, 18.0, 15.0, 15.0, 16.0, 14.0, 16.0, 15.0, 15.0, 16.0, 15.0, 16.0, 15.0, 14.0, 14.0, 15.0, 14.0, 14.0, 15.0, 14.0, 14.0, 14.0, 15.0, 16.0, 14.0, 15.0, 17.0, 14.0, 15.0, 14.0, 15.0, 15.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 14.0, 12.0, 13.0, 15.0, 14.0, 12.0, 12.0, 12.0, 12.0, 14.0, 13.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 13.0, 14.0, 12.0, 13.0, 14.0, 12.0, 12.0, 12.0, 14.0, 10.0, 12.0, 10.0, 10.0, 11.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 11.0, 13.0, 15.0, 14.0, 14.0, 14.0, 14.0, 16.0, 15.0, 14.0, 15.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 16.0, 14.0, 16.0, 14.0, 15.0, 14.0, 14.0, 15.0, 15.0, 11.0, 11.0, 10.0, 11.0, 11.0, 11.0, 16.0, 16.0, 17.0, 22.0, 22.0, 17.0, 16.0, 19.0, 17.0, 16.0, 19.0, 17.0, 22.0, 16.0, 17.0, 16.0, 16.0, 17.0, 16.0, 16.0, 16.0, 14.0, 22.0, 15.0, 16.0, 16.0, 16.0, 15.0, 16.0, 16.0, 14.0, 22.0, 16.0, 15.0, 22.0, 16.0, 15.0, 15.0, 16.0, 19.0, 22.0, 16.0, 15.0, 16.0, 16.0, 15.0, 16.0, 16.0, 15.0, 22.0, 19.0, 15.0, 16.0, 16.0, 15.0, 18.0, 22.0, 16.0, 22.0, 21.0, 16.0, 13.0, 16.0, 16.0, 16.0, 16.0, 16.0, 23.0, 16.0, 16.0, 21.0, 16.0, 16.0, 15.0, 19.0, 14.0, 13.0, 16.0, 22.0, 16.0, 18.0, 22.0, 22.0, 19.0, 22.0, 18.0, 15.0, 16.0, 14.0, 19.0, 16.0, 19.0, 22.0, 16.0, 16.0, 16.0, 15.0, 19.0, 16.0, 16.0, 19.0, 16.0, 16.0, 17.0, 19.0, 19.0, 14.0, 20.0, 14.0, 16.0, 20.0, 15.0, 15.0, 16.0, 19.0, 16.0, 21.0, 22.0, 16.0, 19.0, 19.0, 16.0, 16.0, 16.0, 16.0, 22.0, 23.0, 19.0, 16.0, 16.0, 15.0, 19.0, 16.0, 16.0, 19.0, 22.0, 19.0, 15.0, 16.0, 16.0, 16.0, 15.0, 16.0, 16.0, 16.0, 14.0, 14.0, 21.0, 15.0, 18.0, 13.0, 14.0, 14.0, 21.0, 16.0, 14.0, 19.0, 18.0, 16.0, 21.0, 15.0, 14.0, 16.0, 19.0, 15.0, 14.0, 16.0, 16.0, 15.0, 16.0, 16.0, 15.0, 18.0, 16.0, 16.0, 16.0, 15.0, 16.0, 16.0, 16.0, 13.0, 21.0, 22.0, 16.0, 22.0, 22.0, 16.0, 16.0, 15.0, 16.0, 16.0, 22.0, 14.0, 19.0, 14.0, 16.0, 22.0, 19.0, 16.0, 16.0, 19.0, 16.0, 16.0, 16.0, 14.0, 14.0, 14.0, 16.0, 15.0, 22.0, 16.0, 16.0, 15.0, 16.0, 16.0, 16.0, 19.0, 22.0, 19.0, 16.0, 14.0, 22.0, 23.0, 16.0, 16.0, 22.0, 16.0, 19.0, 16.0, 16.0, 16.0, 19.0, 15.0, 16.0, 16.0, 16.0, 16.0, 14.0, 16.0, 22.0, 16.0, 14.0, 14.0, 16.0, 16.0, 14.0, 22.0, 16.0, 16.0, 16.0, 16.0, 15.0, 16.0, 19.0, 16.0, 19.0, 16.0, 16.0, 16.0, 16.0, 16.0, 14.0, 16.0, 22.0, 16.0, 19.0, 21.0, 19.0, 16.0, 14.0, 22.0, 18.0, 16.0, 14.0, 16.0, 16.0, 19.0, 16.0, 16.0, 15.0, 16.0, 16.0, 16.0, 16.0, 16.0, 22.0, 22.0, 16.0, 16.0, 16.0, 22.0, 16.0, 14.0, 16.0, 16.0, 19.0, 17.0, 22.0, 16.0, 16.0, 19.0, 16.0, 14.0, 16.0, 16.0, 16.0, 16.0, 22.0, 17.0, 16.0, 16.0, 16.0, 17.0, 14.0, 19.0, 16.0, 18.0, 22.0, 16.0, 16.0, 22.0, 14.0, 14.0, 16.0, 16.0, 14.0, 16.0, 16.0, 17.0, 19.0, 22.0, 17.0, 17.0, 19.0, 16.0, 14.0, 20.0, 16.0, 16.0, 15.0, 17.0, 16.0, 14.0, 17.0, 14.0, 21.0, 22.0, 17.0, 15.0, 16.0, 16.0, 17.0, 23.0, 21.0, 16.0, 17.0, 20.0, 18.0, 16.0, 16.0, 17.0, 22.0, 16.0, 23.0, 21.0, 14.0, 16.0, 17.0, 17.0, 16.0, 22.0, 17.0, 17.0, 19.0, 16.0, 15.0, 17.0, 16.0, 22.0, 16.0, 17.0, 16.0, 14.0, 17.0, 16.0, 16.0, 16.0, 22.0, 17.0, 14.0, 16.0, 16.0, 17.0, 14.0, 19.0, 22.0, 17.0, 14.0, 22.0, 16.0, 17.0, 14.0, 16.0, 16.0, 17.0, 16.0, 19.0, 22.0, 18.0, 21.0, 21.0, 17.0, 16.0, 16.0, 17.0, 16.0, 19.0, 17.0, 14.0, 14.0, 17.0, 22.0, 16.0, 17.0, 14.0, 16.0, 17.0, 14.0, 14.0, 17.0, 14.0, 14.0, 17.0, 14.0, 16.0, 17.0, 22.0, 18.0, 17.0, 22.0, 16.0, 16.0, 19.0, 16.0, 17.0, 17.0, 16.0, 17.0, 17.0, 16.0, 14.0, 17.0, 14.0, 16.0, 17.0, 16.0, 19.0, 17.0, 14.0, 16.0, 17.0, 14.0, 19.0, 17.0, 18.0, 19.0, 17.0, 19.0, 16.0, 17.0, 16.0, 16.0, 17.0, 19.0, 21.0, 19.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 14.0, 14.0, 14.0, 11.0, 14.0, 10.0, 14.0, 12.0, 12.0, 11.0, 12.0, 15.0, 11.0, 11.0, 11.0, 9.0, 15.0, 7.0, 12.0, 11.0, 14.0, 9.0, 10.0, 12.0, 11.0, 11.0, 11.0, 11.0, 14.0, 14.0, 14.0, 13.0, 12.0, 13.0, 13.0, 14.0, 14.0, 14.0, 13.0, 13.0, 12.0, 13.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 13.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 12.0, 11.0, 15.0, 11.0, 10.0, 13.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 14.0, 12.0, 12.0, 12.0, 12.0, 12.0, 10.0, 11.0, 10.0, 10.0, 12.0, 12.0, 11.0, 10.0, 13.0, 13.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 13.0, 12.0, 13.0, 13.0, 12.0, 19.0, 14.0, 16.0, 14.0, 16.0, 18.0, 15.0, 14.0, 12.0, 13.0, 12.0, 12.0, 12.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 16.0, 16.0, 16.0, 16.0, 16.0, 14.0, 14.0, 17.0, 14.0, 14.0, 15.0, 14.0, 14.0, 14.0, 14.0, 16.0, 14.0, 13.0, 13.0, 14.0, 14.0, 16.0, 14.0, 12.0, 15.0, 14.0, 16.0, 14.0, 15.0, 14.0, 14.0, 15.0, 14.0, 16.0, 17.0, 13.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 16.0, 14.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 14.0, 14.0, 15.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 16.0, 14.0, 14.0, 14.0, 14.0, 14.0, 15.0, 15.0, 13.0, 14.0, 14.0, 15.0, 13.0, 13.0, 14.0, 15.0, 23.0, 24.0, 14.0, 16.0, 13.0, 13.0, 14.0, 13.0, 13.0, 13.0, 13.0, 15.0, 15.0, 15.0, 15.0, 15.0, 16.0, 14.0, 15.0, 13.0, 13.0, 13.0, 14.0, 16.0, 15.0, 15.0, 12.0, 13.0, 12.0, 12.0, 14.0, 14.0, 13.0, 16.0, 15.0, 13.0, 14.0, 13.0, 13.0, 10.0, 10.0, 15.0, 14.0, 15.0, 18.0, 14.0, 14.0, 17.0, 14.0, 17.0, 17.0, 11.0, 15.0, 20.0, 20.0, 21.0, 21.0, 15.0, 16.0, 20.0, 20.0, 21.0, 13.0, 21.0, 16.0, 16.0, 20.0, 20.0, 21.0, 21.0, 16.0, 16.0, 20.0, 13.0, 20.0, 21.0, 21.0, 16.0, 16.0, 20.0, 20.0, 22.0, 23.0, 16.0, 13.0, 16.0, 20.0, 20.0, 23.0, 16.0, 16.0, 20.0, 20.0, 17.0, 17.0, 13.0, 20.0, 20.0, 17.0, 17.0, 20.0, 13.0, 14.0, 16.0, 13.0, 15.0, 20.0, 15.0, 13.0, 13.0, 13.0, 16.0, 13.0, 19.0, 14.0, 14.0, 14.0, 23.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 15.0, 16.0, 24.0, 17.0, 13.0, 13.0, 19.0, 22.0, 13.0, 18.0, 14.0, 16.0, 16.0, 13.0, 13.0, 13.0, 14.0, 14.0, 21.0, 13.0, 19.0, 18.0, 18.0, 20.0, 20.0, 13.0, 13.0, 18.0, 19.0, 21.0, 21.0, 20.0, 13.0, 13.0, 20.0, 20.0, 21.0, 21.0, 14.0, 20.0, 20.0, 21.0, 13.0, 21.0, 14.0, 14.0, 20.0, 20.0, 21.0, 21.0, 14.0, 14.0, 20.0, 12.0, 20.0, 21.0, 21.0, 14.0, 15.0, 20.0, 20.0, 21.0, 21.0, 15.0, 20.0, 21.0, 22.0, 14.0, 15.0, 15.0, 11.0, 11.0, 10.0, 16.0, 16.0, 16.0, 10.0, 10.0, 10.0, 12.0, 8.0, 12.0, 12.0, 11.0, 12.0, 12.0, 11.0, 11.0, 12.0, 12.0, 10.0, 12.0, 12.0, 11.0, 11.0, 12.0, 11.0, 12.0, 12.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 12.0, 12.0, 11.0, 12.0, 12.0, 11.0, 11.0, 12.0, 12.0, 11.0, 12.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 12.0, 11.0, 11.0, 12.0, 11.0, 12.0, 12.0, 12.0, 12.0, 11.0, 12.0, 11.0, 12.0, 11.0, 12.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 12.0, 12.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 11.0, 11.0, 9.0, 11.0, 11.0, 16.0, 9.0, 12.0, 11.0, 11.0, 10.0, 11.0, 15.0, 15.0, 11.0, 10.0, 16.0, 11.0, 15.0, 11.0, 9.0, 9.0, 12.0, 12.0, 11.0, 12.0, 12.0, 13.0, 13.0, 13.0, 23.0, 18.0, 17.0, 17.0, 15.0, 11.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 14.0, 23.0, 23.0, 12.0, 12.0, 13.0, 18.0, 11.0, 10.0, 17.0, 14.0, 15.0, 14.0, 12.0, 17.0, 15.0, 12.0, 17.0, 16.0, 12.0, 16.0, 14.0, 12.0, 18.0, 11.0, 13.0, 17.0, 16.0, 17.0, 17.0, 17.0, 17.0, 17.0, 18.0, 18.0, 14.0, 14.0, 14.0, 14.0, 15.0, 16.0, 16.0, 18.0, 15.0, 15.0, 13.0, 16.0, 21.0, 14.0, 11.0, 12.0, 15.0, 18.0, 19.0, 19.0, 15.0, 11.0, 15.0, 15.0, 15.0, 15.0, 16.0, 16.0, 15.0, 15.0, 11.0, 16.0, 16.0, 14.0, 10.0, 15.0, 11.0, 21.0, 21.0, 11.0, 21.0, 21.0, 21.0, 15.0, 21.0, 21.0, 21.0, 17.0, 21.0, 21.0, 21.0, 21.0, 12.0, 11.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 14.0, 16.0, 16.0, 17.0, 22.0, 15.0, 16.0, 17.0, 16.0, 21.0, 21.0, 15.0, 20.0, 20.0, 16.0, 23.0, 16.0, 23.0, 15.0, 21.0, 17.0, 15.0, 17.0, 17.0, 20.0, 15.0, 21.0, 16.0, 15.0, 15.0, 17.0, 18.0, 20.0, 19.0, 23.0, 15.0, 21.0, 16.0, 15.0, 22.0, 19.0, 21.0, 19.0, 15.0, 15.0, 21.0, 22.0, 23.0, 20.0, 23.0, 15.0, 20.0, 20.0, 19.0, 16.0, 15.0, 11.0, 10.0, 10.0, 10.0, 11.0, 10.0, 19.0, 11.0, 9.0, 18.0, 9.0, 15.0, 14.0, 15.0, 15.0, 16.0, 10.0, 16.0, 10.0, 10.0, 16.0, 12.0, 15.0, 16.0, 15.0, 10.0, 10.0, 10.0, 12.0, 11.0, 10.0, 16.0, 10.0, 16.0, 16.0, 10.0, 16.0, 13.0, 14.0, 19.0, 10.0, 10.0, 10.0, 14.0, 16.0, 16.0, 9.0, 19.0, 11.0, 11.0, 10.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 13.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 10.0, 12.0, 13.0, 11.0, 13.0, 13.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 12.0, 12.0, 12.0, 11.0, 11.0, 12.0, 12.0, 13.0, 15.0, 24.0, 15.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 12.0, 12.0, 13.0, 12.0, 14.0, 14.0, 14.0, 14.0, 13.0, 15.0, 15.0, 12.0, 15.0, 21.0, 15.0, 11.0, 15.0, 15.0, 19.0, 15.0, 15.0, 14.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 22.0, 22.0, 11.0, 11.0, 13.0, 12.0, 21.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 12.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 12.0, 16.0, 16.0, 16.0, 16.0, 16.0, 14.0, 10.0, 15.0, 13.0, 14.0, 12.0, 17.0, 13.0, 14.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 14.0, 13.0, 14.0, 14.0, 10.0, 13.0, 13.0, 22.0, 14.0, 14.0, 13.0, 14.0, 14.0, 24.0, 25.0, 15.0, 22.0, 12.0, 12.0, 12.0, 13.0, 11.0, 14.0, 14.0, 14.0, 26.0, 25.0, 15.0, 13.0, 13.0, 13.0, 13.0, 11.0, 24.0, 25.0, 21.0, 14.0, 11.0, 13.0, 15.0, 15.0, 15.0, 13.0, 23.0, 19.0, 17.0, 22.0, 15.0, 15.0, 15.0, 10.0, 13.0, 14.0, 17.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.0, 13.0, 13.0, 17.0, 17.0, 15.0, 14.0, 13.0, 14.0, 13.0, 18.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 16.0, 17.0, 18.0, 13.0, 15.0, 15.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 13.0, 18.0, 16.0, 13.0, 13.0, 13.0, 16.0, 15.0, 16.0, 13.0, 13.0, 17.0, 17.0, 16.0, 16.0, 13.0, 13.0, 17.0, 16.0, 17.0, 14.0, 13.0, 16.0, 13.0, 14.0, 14.0, 14.0, 13.0, 17.0, 17.0, 14.0, 17.0, 20.0, 13.0, 13.0, 13.0, 13.0, 21.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 17.0, 12.0, 14.0, 13.0, 13.0, 11.0, 13.0, 10.0, 13.0, 14.0, 14.0, 14.0, 17.0, 13.0, 14.0, 14.0, 14.0, 14.0, 10.0, 10.0, 10.0, 15.0, 13.0, 13.0, 15.0, 18.0, 15.0, 21.0, 11.0, 12.0, 14.0, 14.0, 16.0, 15.0, 14.0, 14.0, 14.0, 14.0, 18.0, 17.0, 17.0, 17.0, 13.0, 17.0, 16.0, 15.0, 15.0, 18.0, 16.0, 19.0, 19.0, 15.0, 15.0, 13.0, 15.0, 15.0, 15.0, 16.0, 16.0, 16.0, 17.0, 15.0, 15.0, 14.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 15.0, 14.0, 13.0, 15.0, 13.0, 13.0, 12.0, 13.0, 13.0, 14.0, 14.0, 14.0, 15.0, 15.0, 15.0, 14.0, 14.0, 13.0, 13.0, 13.0, 14.0, 13.0, 14.0, 14.0, 13.0, 28.0, 13.0, 15.0, 16.0, 16.0, 14.0, 14.0, 15.0, 15.0, 13.0, 15.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 16.0, 14.0, 14.0, 14.0, 14.0, 13.0, 14.0, 16.0, 14.0, 15.0, 14.0, 16.0, 14.0, 15.0, 14.0, 14.0, 14.0, 13.0, 14.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 15.0, 12.0, 12.0, 12.0, 12.0, 14.0, 12.0, 10.0, 12.0, 12.0, 10.0, 10.0, 12.0, 12.0, 14.0, 17.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 14.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 12.0, 16.0, 12.0, 12.0, 12.0, 12.0, 11.0, 12.0, 12.0, 12.0, 17.0, 12.0, 18.0, 13.0, 15.0, 13.0, 14.0, 17.0, 12.0, 11.0, 17.0, 17.0, 12.0, 17.0, 11.0, 17.0, 12.0, 17.0, 10.0, 17.0, 11.0, 17.0, 14.0, 17.0, 14.0, 17.0, 14.0, 18.0, 14.0, 18.0, 16.0, 12.0, 12.0, 18.0, 12.0, 18.0, 11.0, 12.0, 12.0, 12.0, 14.0, 16.0, 12.0, 14.0, 17.0, 16.0, 12.0, 11.0, 12.0, 11.0, 14.0, 12.0, 11.0, 18.0, 12.0, 13.0, 14.0, 14.0, 12.0, 14.0, 14.0, 14.0, 14.0, 14.0, 17.0, 10.0, 12.0, 10.0, 12.0, 11.0, 14.0, 12.0, 14.0, 14.0, 12.0, 16.0, 14.0, 13.0, 14.0, 12.0, 14.0, 14.0, 14.0, 11.0, 14.0, 12.0, 12.0, 10.0, 12.0, 10.0, 12.0, 10.0, 12.0, 11.0, 12.0, 14.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 12.0, 12.0, 16.0, 12.0, 17.0, 12.0, 13.0, 12.0, 13.0, 12.0, 11.0, 12.0, 13.0, 12.0, 12.0, 12.0, 14.0, 12.0, 11.0, 12.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 12.0, 12.0, 17.0, 12.0, 12.0, 12.0, 12.0, 14.0, 12.0, 12.0, 14.0, 12.0, 12.0, 11.0, 12.0, 12.0, 12.0, 12.0, 11.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 13.0, 11.0, 12.0, 13.0, 17.0, 12.0, 12.0, 12.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 14.0, 13.0, 14.0, 13.0, 13.0, 14.0, 13.0, 14.0, 14.0, 14.0, 14.0, 27.0, 27.0, 28.0, 14.0, 14.0, 14.0, 13.0, 12.0, 12.0, 14.0, 14.0, 25.0, 14.0, 14.0, 15.0, 15.0, 15.0, 15.0, 16.0, 14.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 8.0, 17.0, 11.0, 10.0, 5.0, 7.0, 10.0, 10.0, 5.0, 6.0, 8.0, 12.0, 8.0, 2.0, 2.0, 4.0, 2.0, 4.0, 12.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0, 9.0, 4.0, 8.0, 4.0, 6.0, 4.0, 7.0, 4.0, 12.0, 9.0, 8.0, 9.0, 5.0, 5.0, 10.0, 8.0, 10.0, 10.0, 10.0, 10.0, 10.0, 5.0, 4.0, 7.0, 8.0, 11.0, 7.0, 11.0, 6.0, 6.0, 6.0, 6.0, 7.0, 6.0, 6.0, 10.0, 5.0, 11.0, 6.0, 6.0, 10.0, 10.0, 7.0, 7.0, 9.0, 16.0, 15.0, 19.0, 15.0, 15.0, 14.0, 14.0, 14.0, 16.0, 15.0]\n",
            "(7886, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XXuLOCdmIf5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "bffb9ee8-9e1c-4da2-b2ab-adca66aa9b94"
      },
      "cell_type": "code",
      "source": [
        "print(y_data)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lTi2uUYxHUBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bf72abd-b03f-488c-b508-b101f5e851e9"
      },
      "cell_type": "code",
      "source": [
        "print(y_data[4563])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9qR7C_R1HBU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab69237b-f1f1-48a4-c089-8c7bab417050"
      },
      "cell_type": "code",
      "source": [
        "print(min(y_data1),max(y_data1))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 29.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YXbXk8pohRlA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d415cc1-7d35-43d9-f132-bf78b4f64626"
      },
      "cell_type": "code",
      "source": [
        "print(len(x_data),len(y_data))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7886 7886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_HDUqjfDm-tM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93436302-bd90-4542-959b-602f653b08cb"
      },
      "cell_type": "code",
      "source": [
        "type(x_data)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "hsV4RQnwYw9U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# np.shape(x_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QqVey763YUn1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for i,ele in x_data:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAPrpc6fSn2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from array import array\n",
        "# a = np.array([7886, img_width,img_height,3]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C6SEZnlne6Rq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_dataset = np.ndarray(shape=(len(x_data), img_width, img_height, 3),\n",
        "#                          dtype=np.float32)\n",
        "\n",
        "# for i,ele in enumerate(x_data):\n",
        "#   x_dataset[i,:,:] = ele\n",
        "  \n",
        "  \n",
        "# print(len(x_dataset),type(x_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8ztmTLf0puk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RThwon02X-2A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(len(a),np.shape(a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0LOajQKBXllp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# len(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2TQpPDkhSqYR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a.append(x_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l2paHF4WRBWa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a = np.ones((len(x_data),img_width,img_width,3)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDdC3xxLNioM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from array import array\n",
        "# intarray = array('i')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IVde2Kh-Pk5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(type(intarray),np.shape(intarray),len(intarray))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DlAdCAizPzCT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# intarray.append(x_data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WK0nNHelP31n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# len(intarray)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SLNJiR1ie_JI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_data1 = np.array(x_data)\n",
        "\n",
        "# print (x_data1.shape)\n",
        "# img_data=np.rollaxis(x_data1,1,0)\n",
        "# print (img_data.shape)\n",
        "# img_data=img_data[0]\n",
        "# print (img_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CnKk3plmih6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7c56674-30db-43bd-d712-59442db10cb5"
      },
      "cell_type": "code",
      "source": [
        "print(np.shape(x_data[0]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "li202ZxXf9CM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(len(x_data))\n",
        "# x_data2 = []\n",
        "# y_data2 = []\n",
        "# for i in range(0,2000):\n",
        "#   x_data2.append(x_data[i][0])\n",
        "#   y_data2.append(y_data[i])\n",
        "\n",
        "# print(len(x_data2))\n",
        "\n",
        "\n",
        "# print(np.shape(x_data2))\n",
        "\n",
        "\n",
        "# x_data3 = np.array(x_data2)\n",
        "# print(type(x_data3))\n",
        "# print(np.shape(x_data3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "60CfyCOug1df",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(len(x_data3),len(y_data2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Umc3amO5fAl9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset\n",
        "x,y = shuffle(x_data,y_data, random_state=2)\n",
        "# # Split the dataset\n",
        "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
        "\n",
        "# num_classes = np.shape(y_data[1])\n",
        "# # num_of_samples = img_data.shape[0]\n",
        "\n",
        "# # print(np.shape(X_train))\n",
        "# # print(np.shape(X_test))\n",
        "# # print(np.shape(y_train))\n",
        "# # print(np.shape(y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4mDL40dSq59j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fbea16d-6fdd-4a2d-99bf-d25acd118d24"
      },
      "cell_type": "code",
      "source": [
        "a = len(x)\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "for i in range(0,a):\n",
        "  if i < a*0.8:\n",
        "    X_train.append(x[i])\n",
        "    y_train.append(y[i])\n",
        "  else:\n",
        "    X_test.append(x[i])\n",
        "    y_test.append(y[i])\n",
        "    \n",
        "print(len(X_train), len(X_test), len(y_train), len(y_test))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6309 1577 6309 1577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O5QwvZ5oAulz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S_5G78qTfCda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#freeze the few(1st five) layers for undesirable change\n",
        "\n",
        "# for layer in model.layers[:4]:\n",
        "#   layer.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "865vO35jfDW6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #adding custom layers\n",
        "# x1 = model.output\n",
        "# x1 = Flatten()(x1)\n",
        "# x1 = Dense(1024, activation=\"relu\")(x1)\n",
        "# x1 = Dropout(0.5)(x1)\n",
        "# x1 = Dense(1024,activation=\"relu\")(x1)\n",
        "# predictions = Dense(30,activation=\"softmax\", name='output_layer')(x1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LQaUhknCfHDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #create final model\n",
        "# model_final = Model(input=model.input, output = predictions)\n",
        "\n",
        "\n",
        "# # model_final.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vajN-ogGYhw4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# filepath = \"model_final4.h5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "# callbacks_list = [checkpoint]\n",
        "\n",
        "# # fit the model\n",
        "# model.fit(x_train, y_train, epochs=5, batch_size=50, callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p50xu7LFfJ0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# filepath = \"model_final4.h5\"\n",
        "# checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "# callbacks_list = [checkpoint]\n",
        "\n",
        "\n",
        "# model_final.compile(loss='categorical_crossentropy',optimizer= optimizers.RMSprop(lr=1e-5),metrics=['accuracy'])\n",
        "\n",
        "# t=time.time()\n",
        "# hist = model_final.fit(X_train, y_train, batch_size=8, epochs=5, verbose=1, validation_data=(X_test, y_test), callbacks=callbacks_list)\n",
        "# print('Training time: %s' % (t - time.time()))\n",
        "# (loss, accuracy) = model_final.evaluate(X_test, y_test, batch_size=10, verbose=1)\n",
        "\n",
        "# print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UWBJgxFofL8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# # visualizing losses and accuracy\n",
        "# train_loss=hist.history['loss']\n",
        "# val_loss=hist.history['val_loss']\n",
        "# train_acc=hist.history['acc']\n",
        "# val_acc=hist.history['val_acc']\n",
        "# xc=range(5)\n",
        "\n",
        "\n",
        "\n",
        "# plt.figure(1,figsize=(7,5))\n",
        "# plt.plot(xc,train_loss)\n",
        "# plt.plot(xc,val_loss)\n",
        "# plt.xlabel('num of Epochs')\n",
        "# plt.ylabel('loss')\n",
        "# plt.title('train_loss vs val_loss')\n",
        "# plt.grid(True)\n",
        "# plt.legend(['train','val'])\n",
        "# #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "# plt.style.use(['classic'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# plt.figure(2,figsize=(7,5))\n",
        "# plt.plot(xc,train_acc)\n",
        "# plt.plot(xc,val_acc)\n",
        "# plt.xlabel('num of Epochs')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.title('train_acc vs val_acc')\n",
        "# plt.grid(True)\n",
        "# plt.legend(['train','val'],loc=4)\n",
        "# #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "# plt.style.use(['classic'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ifZp3YjQqpUK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ZdwonvLp7Ec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainsubpart(x_temp_train, y_temp_train,x_temp_test, y_temp_test,flag,n_epochs):\n",
        "\n",
        "  if flag == 1:\n",
        "    model_final4 = load_model('model_final4.h5')\n",
        "  elif flag == 0:\n",
        "    x1 = model.output\n",
        "    x1 = Flatten()(x1)\n",
        "    x1 = Dense(1024, activation=\"relu\")(x1)\n",
        "    x1 = Dropout(0.5)(x1)\n",
        "    x1 = Dense(1024,activation=\"relu\")(x1)\n",
        "    predictions = Dense(30,activation=\"softmax\", name='output_layer')(x1)\n",
        "    \n",
        "    \n",
        "    model_final = Model(input=model.input, output = predictions)\n",
        "    \n",
        "    model_final.compile(loss='categorical_crossentropy',optimizer= optimizers.RMSprop(lr=1e-5),metrics=['accuracy'])\n",
        "    \n",
        "\n",
        "    model_final4 = model_final\n",
        "    \n",
        "    \n",
        "    \n",
        "  x_temp_train = np.array(x_temp_train)\n",
        "  y_temp_train = np.array(y_temp_train)\n",
        "  x_temp_test = np.array(x_temp_test)\n",
        "  y_temp_test = np.array(y_temp_test)\n",
        "  \n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "  callbacks_list = [checkpoint]\n",
        "\n",
        "#   x4,y4 = shuffle(x_temp,y_temp, random_state=2)\n",
        "#   X_train4, X_test4, y_train4, y_test4 = train_test_split(x4, y4, test_size=0.2, random_state=2)\n",
        "\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "  # model_final4.compile(loss='categorical_crossentropy',optimizer= optimizers.RMSprop(lr=1e-5),metrics=['accuracy'])\n",
        "\n",
        "  t=time.time()\n",
        "  hist = model_final4.fit(x_temp_train, y_temp_train, batch_size=8, epochs=n_epochs, verbose=1, validation_data=(x_temp_test, y_temp_test), callbacks=callbacks_list)\n",
        "#   print('Training time: %s' % (t - time.time()))\n",
        "  (loss, accuracy) = model_final4.evaluate(x_temp_test, y_temp_test, batch_size=10, verbose=1)\n",
        "\n",
        "#   print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # visualizing losses and accuracy\n",
        "  train_loss=hist.history['loss']\n",
        "  val_loss=hist.history['val_loss']\n",
        "  train_acc=hist.history['acc']\n",
        "  val_acc=hist.history['val_acc']\n",
        "  xc=range(n_epochs)\n",
        "\n",
        "\n",
        "\n",
        "  plt.figure(1,figsize=(7,5))\n",
        "  plt.plot(xc,train_loss)\n",
        "  plt.plot(xc,val_loss)\n",
        "  plt.xlabel('num of Epochs')\n",
        "  plt.ylabel('loss')\n",
        "  plt.title('train_loss vs val_loss')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train','val'])\n",
        "  #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "  plt.style.use(['classic'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  plt.figure(2,figsize=(7,5))\n",
        "  plt.plot(xc,train_acc)\n",
        "  plt.plot(xc,val_acc)\n",
        "  plt.xlabel('num of Epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.title('train_acc vs val_acc')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train','val'],loc=4)\n",
        "  #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
        "  plt.style.use(['classic'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wrAKbBYgqJI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# trainsubpart(x_temp, y_temp,flag)\n",
        "def bypart_train(flag):\n",
        "  \n",
        "  n_epochs = 1\n",
        "  \n",
        "  # model_final4.compile(loss='categorical_crossentropy',optimizer= optimizers.RMSprop(lr=1e-5),metrics=['accuracy'])\n",
        "  # filepath = 'model_final4.h5'\n",
        "  \n",
        "  for i in range(0,4):\n",
        "    print(\"\\n\\n\\n\\n-------------\" + str(i)+\"--------------------------------\\n\\n\\n\\n\\n\\n\\n\")\n",
        "    a = len(X_train)//4\n",
        "    b = len(X_test)//4\n",
        "    \n",
        "    x_temp_train = []\n",
        "    y_temp_train = []\n",
        "    print(i*a,(i+1)*a)\n",
        "    for j in range(i*a, (i+1)*a):\n",
        "      x_temp_train.append(X_train[j])\n",
        "      y_temp_train.append(y_train[j])\n",
        "      \n",
        "    x_temp_test = []\n",
        "    y_temp_test = []\n",
        "    print(i*b,(i+1)*b)\n",
        "    for k in range(i*b, (i+1)*b):\n",
        "      x_temp_test.append(X_test[k])\n",
        "      y_temp_test.append(y_test[k])\n",
        "  \n",
        "    trainsubpart(x_temp_train, y_temp_train,x_temp_test, y_temp_test,flag, n_epochs)\n",
        "  \n",
        "    flag = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-dJ34VpYoxB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def checkacc(x_temp, y_temp):\n",
        "  \n",
        "  model_final5 = load_model('model_final4.h5')\n",
        "  (loss, accuracy) = model_final5.evaluate(x_temp, y_temp, batch_size=10, verbose=1)\n",
        "\n",
        "  print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,accuracy * 100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u18d_4fdXhmn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "collapsed": true,
        "outputId": "d89e7a5f-5260-4c95-8fec-dbcc6e15a3f3"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "flag = 0\n",
        "filepath = 'model_final4.h5'\n",
        "for e in range(0,10):\n",
        "  print(\"***********************************************( \"+str(e)+\" )********\")\n",
        "  bypart_train(flag)\n",
        "  x_temp = np.array(X_test)\n",
        "  y_temp = np.array(y_test)\n",
        "  checkacc(x_temp, y_temp)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***********************************************( 0 )********\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "-------------0--------------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8ebc447c185c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flag = 0\\nfilepath = \\'model_final4.h5\\'\\nfor e in range(0,10):\\n  print(\"***********************************************( \"+str(e)+\" )********\")\\n  bypart_train(flag)\\n  x_temp = np.array(X_test)\\n  y_temp = np.array(y_test)\\n  checkacc(x_temp, y_temp)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4a91809e43fb>\u001b[0m in \u001b[0;36mbypart_train\u001b[0;34m(flag)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n\\n\\n-------------\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"--------------------------------\\n\\n\\n\\n\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "95GpQB1YqRIG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BtTg2AkSqWs-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_temp = np.array(X_test)\n",
        "# y_temp = np.array(y_test)\n",
        "# checkacc(x_temp, y_temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XCS0mOyYCE7p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}